/data/users/pianpwk/pytorch/torch/cuda/__init__.py:64: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
I1015 13:43:36.829000 4148767 torch/_inductor/config.py:895] compile_threads set to 32
[rank0]:I1015 13:43:37.956000 4148767 torch/_dynamo/utils.py:1763] [0/0] ChromiumEventLogger initialized with id 230d7d0e-70d1-4b38-ac02-c97362c030c6
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0] torchdynamo start compiling fn /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py:573, stack (elided 4 frames):
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py", line 588, in <module>
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     run_tests()
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/data/users/pianpwk/pytorch/torch/testing/_internal/common_utils.py", line 1399, in run_tests
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     unittest.main(argv=argv)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/main.py", line 101, in __init__
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     self.runTests()
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/main.py", line 271, in runTests
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     self.result = testRunner.run(self.test)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/runner.py", line 184, in run
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     test(result)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/suite.py", line 84, in __call__
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     return self.run(*args, **kwds)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/suite.py", line 122, in run
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     test(result)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/suite.py", line 84, in __call__
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     return self.run(*args, **kwds)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/suite.py", line 122, in run
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     test(result)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/case.py", line 650, in __call__
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     return self.run(*args, **kwds)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/data/users/pianpwk/pytorch/torch/testing/_internal/common_utils.py", line 3460, in run
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     self._run_custom(
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/data/users/pianpwk/pytorch/torch/testing/_internal/common_utils.py", line 3430, in _run_custom
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     super_run(result=result)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/case.py", line 591, in run
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     self._callTestMethod(testMethod)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/home/pianpwk/.conda/envs/pytorch-3848/lib/python3.10/unittest/case.py", line 549, in _callTestMethod
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     method()
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/data/users/pianpwk/pytorch/torch/testing/_internal/common_utils.py", line 3278, in wrapper
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     method(*args, **kwargs)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]   File "/data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py", line 578, in test_inductor_calls_for_mm
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0]     out = fn(x_dtensor, y_dtensor)
[rank0]:V1015 13:43:37.956000 4148767 torch/_dynamo/convert_frame.py:1543] [0/0] 
[rank0]:I1015 13:43:37.957000 4148767 torch/_dynamo/symbolic_convert.py:4215] [0/0] Step 1: torchdynamo start tracing fn /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py:573
[rank0]:I1015 13:43:37.957000 4148767 torch/fx/experimental/symbolic_shapes.py:3820] [0/0] create_env
[rank0]:V1015 13:43:37.959000 4148767 torch/_dynamo/symbolic_convert.py:1333] [0/0] [__trace_source] TRACE starts_line /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py:575 in fn (TestDTensorDebugMode.test_inductor_calls_for_mm.fn)
[rank0]:V1015 13:43:37.959000 4148767 torch/_dynamo/symbolic_convert.py:1333] [0/0] [__trace_source]                 return torch.mm(x, y)
[rank0]:V1015 13:43:37.966000 4148767 torch/_dynamo/symbolic_convert.py:1359] [0/0] [__trace_bytecode] TRACE LOAD_GLOBAL torch []
[rank0]:V1015 13:43:37.966000 4148767 torch/_dynamo/symbolic_convert.py:1359] [0/0] [__trace_bytecode] TRACE LOAD_ATTR mm [LazyVariableTracker()]
[rank0]:V1015 13:43:38.006000 4148767 torch/_dynamo/symbolic_convert.py:1359] [0/0] [__trace_bytecode] TRACE LOAD_FAST x [LazyVariableTracker()]
[rank0]:V1015 13:43:38.007000 4148767 torch/_dynamo/symbolic_convert.py:1359] [0/0] [__trace_bytecode] TRACE LOAD_FAST y [LazyVariableTracker(), LazyVariableTracker()]
[rank0]:V1015 13:43:38.007000 4148767 torch/_dynamo/symbolic_convert.py:1359] [0/0] [__trace_bytecode] TRACE CALL_FUNCTION 2 [LazyVariableTracker(), LazyVariableTracker(), LazyVariableTracker()]
[rank0]:V1015 13:43:38.013000 4148767 torch/_dynamo/variables/builder.py:3561] [0/0] wrap_to_fake L['x'] (8, 8) SubclassSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}, inner_contexts={'_local_tensor': StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=AttrSource(base=AttrSource(base=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), member='_base'), shape_env_to_source_to_symbol_cache={}), tensor_source=AttrSource(base=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), shape_env_to_source_to_symbol_cache={})}) <class 'torch.distributed.tensor.DTensor'>
[rank0]:V1015 13:43:38.016000 4148767 torch/_dynamo/variables/builder.py:3561] [0/0] wrap_to_fake L['x']._local_tensor (1, 8) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=AttrSource(base=AttrSource(base=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), member='_base'), shape_env_to_source_to_symbol_cache={140660247269088: {"L['x']._local_tensor._base.size()[0]": 1, "L['x']._local_tensor._base.size()[1]": 8, "L['x']._local_tensor._base.storage_offset()": 0}}), tensor_source=AttrSource(base=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), shape_env_to_source_to_symbol_cache={140660247269088: {"L['x']._local_tensor.size()[0]": 1, "L['x']._local_tensor.size()[1]": 8, "L['x']._local_tensor.storage_offset()": 0}}) <class 'torch.Tensor'>
[rank0]:V1015 13:43:38.016000 4148767 torch/_dynamo/output_graph.py:3225] [0/0] create_graph_input L_x_ L['x'] DTensor(local_tensor=FakeTensor(..., device='cuda:0', size=(1, 8)), device_mesh=DeviceMesh((8,), 'cuda', stride=(1,)), placements=(Shard(dim=0),)) at debug_level 0 before=False
[rank0]:V1015 13:43:38.017000 4148767 torch/_dynamo/variables/builder.py:3561] [0/0] wrap_to_fake L['x']._local_tensor (1, 8) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=AttrSource(base=AttrSource(base=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), member='_base'), shape_env_to_source_to_symbol_cache={}), tensor_source=AttrSource(base=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), shape_env_to_source_to_symbol_cache={140660247269088: {"L['x']._local_tensor.size()[0]": 1, "L['x']._local_tensor.size()[1]": 8, "L['x']._local_tensor.storage_offset()": 0}}) <class 'torch.Tensor'>
[rank0]:V1015 13:43:38.017000 4148767 torch/_dynamo/output_graph.py:3225] [0/0] create_graph_input L_x_local_tensor L['x']._local_tensor FakeTensor(..., device='cuda:0', size=(1, 8)) at debug_level 0 before=False
[rank0]:V1015 13:43:38.018000 4148767 torch/_dynamo/variables/builder.py:3561] [0/0] wrap_to_fake L['x']._local_tensor._base (1, 8) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=AttrSource(base=AttrSource(base=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), member='_base'), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
[rank0]:V1015 13:43:38.018000 4148767 torch/_dynamo/variables/builder.py:3561] [0/0] wrap_to_fake L['y'] (8, 32) SubclassSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}, inner_contexts={'_local_tensor': StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=AttrSource(base=AttrSource(base=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), member='_base'), shape_env_to_source_to_symbol_cache={}), tensor_source=AttrSource(base=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), shape_env_to_source_to_symbol_cache={})}) <class 'torch.distributed.tensor.DTensor'>
[rank0]:V1015 13:43:38.026000 4148767 torch/_dynamo/variables/builder.py:3561] [0/0] wrap_to_fake L['y']._local_tensor (1, 32) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=AttrSource(base=AttrSource(base=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), member='_base'), shape_env_to_source_to_symbol_cache={140660247269088: {"L['y']._local_tensor._base.size()[0]": 1, "L['y']._local_tensor._base.size()[1]": 32, "L['y']._local_tensor._base.storage_offset()": 0}}), tensor_source=AttrSource(base=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), shape_env_to_source_to_symbol_cache={140660247269088: {"L['y']._local_tensor.size()[0]": 1, "L['y']._local_tensor.size()[1]": 32, "L['y']._local_tensor.storage_offset()": 0}}) <class 'torch.Tensor'>
[rank0]:V1015 13:43:38.026000 4148767 torch/_dynamo/output_graph.py:3225] [0/0] create_graph_input L_y_ L['y'] DTensor(local_tensor=FakeTensor(..., device='cuda:0', size=(1, 32)), device_mesh=DeviceMesh((8,), 'cuda', stride=(1,)), placements=(Shard(dim=0),)) at debug_level 0 before=False
[rank0]:V1015 13:43:38.027000 4148767 torch/_dynamo/variables/builder.py:3561] [0/0] wrap_to_fake L['y']._local_tensor (1, 32) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=AttrSource(base=AttrSource(base=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), member='_base'), shape_env_to_source_to_symbol_cache={}), tensor_source=AttrSource(base=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), shape_env_to_source_to_symbol_cache={140660247269088: {"L['y']._local_tensor.size()[0]": 1, "L['y']._local_tensor.size()[1]": 32, "L['y']._local_tensor.storage_offset()": 0}}) <class 'torch.Tensor'>
[rank0]:V1015 13:43:38.027000 4148767 torch/_dynamo/output_graph.py:3225] [0/0] create_graph_input L_y_local_tensor L['y']._local_tensor FakeTensor(..., device='cuda:0', size=(1, 32), requires_grad=True) at debug_level 0 before=False
[rank0]:V1015 13:43:38.028000 4148767 torch/_dynamo/variables/builder.py:3561] [0/0] wrap_to_fake L['y']._local_tensor._base (1, 32) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>], dynamic_strides=[<DimDynamic.INFER_STRIDE: 4>, <DimDynamic.INFER_STRIDE: 4>], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=AttrSource(base=AttrSource(base=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), member='_local_tensor'), member='_base'), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
[rank0]:V1015 13:43:38.031000 4148767 torch/_dynamo/symbolic_convert.py:1359] [0/0] [__trace_bytecode] TRACE RETURN_VALUE None [TensorVariable()]
[rank0]:I1015 13:43:38.031000 4148767 torch/_dynamo/symbolic_convert.py:4434] [0/0] Step 1: torchdynamo done tracing fn (RETURN_VALUE)
[rank0]:V1015 13:43:38.032000 4148767 torch/_dynamo/symbolic_convert.py:4438] [0/0] RETURN_VALUE triggered compile
[rank0]:V1015 13:43:38.032000 4148767 torch/_dynamo/output_graph.py:1455] [0/0] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py, line 575 in fn>], graph_break=False)
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2499] [0/0] REMOVE UNUSED GRAPHARG L['x']._local_tensor
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2499] [0/0] REMOVE UNUSED GRAPHARG L['y']._local_tensor
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code] TRACED GRAPH
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]  ===== __compiled_fn_1_9285c021_4182_4639_89a0_fcadd8d40499 =====
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]  /data/users/pianpwk/pytorch/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]     def forward(self, L_x_: "DTensor(f32[8, 8][8, 1]cuda:0)", L_y_: "DTensor(f32[8, 32][32, 1]cuda:0)"):
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]         l_x_ = L_x_
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]         l_y_ = L_y_
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]         
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]          # File: /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py:575 in fn, code: return torch.mm(x, y)
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]         mm: "DTensor(f32[8, 32][32, 1]cuda:0)" = torch.mm(l_x_, l_y_);  l_x_ = l_y_ = None
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]         return (mm,)
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code]         
[rank0]:V1015 13:43:38.033000 4148767 torch/_dynamo/output_graph.py:2154] [0/0] [__graph_code] 
[rank0]:I1015 13:43:38.034000 4148767 torch/_dynamo/output_graph.py:2338] [0/0] Step 2: calling compiler function inductor
[rank0]:I1015 13:43:38.815000 4148767 torch/_inductor/async_compile.py:269] [0/0] Creating 'subprocess' pool with 32 workers
[rank0]:I1015 13:43:38.924000 4148767 torch/_inductor/compile_worker/subproc_pool.py:166] [0/0] Suppressing compile worker output due to config
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs] TRACED GRAPH
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]  ===== BEFORE PRE GRAD =====
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]  /data/users/pianpwk/pytorch/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]     def forward(self, L_x_: "DTensor(f32[8, 8][8, 1]cuda:0)", L_y_: "DTensor(f32[8, 32][32, 1]cuda:0)"):
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]         l_x_ = L_x_
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]         l_y_ = L_y_
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]         
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]          # File: /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py:575 in fn, code: return torch.mm(x, y)
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]         mm: "DTensor(f32[8, 32][32, 1]cuda:0)" = torch.mm(l_x_, l_y_);  l_x_ = l_y_ = None
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]         return (mm,)
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs]         
[rank0]:V1015 13:43:38.925000 4148767 torch/_inductor/compile_fx.py:2383] [0/0] [__pre_grad_graphs] 
[rank0]:V1015 13:43:39.572000 4148767 torch/_inductor/compile_fx.py:883] [0/0] FX cache status: use_cache=True, local=True, remote=False, aot_mode=False, force_disable_caches=False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] FX graph cache hash details for key frlw45brionirhnoxrfjs5td5al4k5x5jtbtkx4adru4kflp3eho:
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [bi6ff7autshatvtuzx46crymzwehd4lcgudr3my47rxpb57fomg] gm: GraphModule()
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] def forward(self, primals_1, primals_2):
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0]     all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(primals_2, 8, '0');  primals_2 = None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0]     wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0]     mm = torch.ops.aten.mm.default(primals_1, wait_tensor);  wait_tensor = None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0]     permute = torch.ops.aten.permute.default(primals_1, [1, 0]);  primals_1 = None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0]     return (mm, permute)
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0]     
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] # To see more debug info, please use `graph_module.print_readable()`
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [zoazjt227asg3kzgdklrwckcqnk3tqdxbo6vozec3vzx5yfdppm] example_inputs[0]: TensorMetadata(dtype=torch.float32, shape=torch.Size([1, 8]), stride=(8, 1), device=device(type='cuda', index=0), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [twrt7dztsuqw6xffr3c4vdvwseclkp2od2nfidfqyapsj6z2lqe] example_inputs[1]: TensorMetadata(dtype=torch.float32, shape=torch.Size([1, 32]), stride=(32, 1), device=device(type='cuda', index=0), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[fx_wrapper]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_backward]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] fx_kwargs[static_input_idxs]: []
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inputs_to_check[0]: 0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[1]: 1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [kf4pkt4tzlxrqjlyx7qoq54jgkkbevnea23xjd2e7ocd2ssq2uy] torch_version: ��B|�#�l�f�^X�nh���t�9TN�'�ʙZ
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [poglqjwowp4gnkmehjby2lvdjrwuo5tbxa2gayd6smgasl2hgsd] system_info[device]: {'name': 'NVIDIA H100'}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [gmdy3xpmssv2cijclukk43v25pzgfxwpb6e4z4sfiwmaelle6i5] system_info[version]: {'triton': '3.5.00355c3e3452fa4500122244b8fff8864f22bc05c417a3d6f5dada9f2e92f8040-c4d799c32eb6a3b92ad36ad7ea5645efc5b2fc6cd5c73dadc3a678d57dd2ccf4-c37149275a03d063fc1c339cd76a19da1c17e3d555410372e6cad29eedef6202-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-03bffcc16c9d6be5ea8fde645caf3a6e3c0ac892eec49051a79d4cc99b66b9c7-e68505098eef3e7c0b050cb91da2587ab6c10d455ca0b941ff06fa8068e16305-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-25cb0bee9547488335de2d495af738298ba6d4c20f1d37941dc17751c57a211e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-3e3d33fbab70c7c05fc70e2e2fdd763dca0b847f62150592b99f8886a419ee64-83ef58f2371da7ad8e01822c2afc82f9a2d6516c2249ee0bbd8873bb20616be0-428d70cb058f1fffef47a6dbcc0be1a84551011aa2203dd5a6a613a6180e9c2f-5c1281b67c0d949da34ccf1c3b68804a2caa2665953984d837d753e91af611fe-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-adb54e71d0ffc3bdac437fbc97929769fbbe4ebd03e6361c6357f2a24f7c5954-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-18572e33e474a820799036f2b2f8c3e54d8a526386356716cccf2bf32a832376-2cdca74c4297804dcf499a7e9d4315ab87edfe2d72f536a8fdc02f28a3e7dacd-b53abe93473eb37d88bc378692065c9a8b1bf54b6417cb1911a13d10918c6d20-f60c2bb2d8eebe1c191f4b8b819844414dd1bce243645635a094f9f92665a58e-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-3db4bee9427c7eb0e2105aff484bdacc819357d298e8f6e89c372ae9c3625bdf-59cf295f3aab4fa62b96a627aa9fec1302950133750de59e542c7b4c9e5b80b6-5305890c3b133def44e2f3d3405e0fb1fd6ce78d0a28b2127670a195bbe11c66', 'cuda': '12.4'}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4dqne2ki3ebfnda5zvbe7wpqn3aw5vd6zyzhi735zdflhcvrrc2] system_info[hash]: 453a6d85f75096fc411d286136956c3fec25ea7f8d879b9957960fb1eefe4d41
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[worker_log_path]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[remote_gemm_autotune_cache]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fx_wrapper]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[custom_partitioner_fn]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_peak_memory_debug]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[size_threshold_for_succ_based_strategy]: 0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_iterative_debug_memory_recompute]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[env_str]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_iterative_debug_limit_to_reorder]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sink_waits_iterative_debug_limit_to_sink]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[runtime_estimations_mms_benchmark]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_prune_choices_based_on_shared_mem]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton_disable_device_detection]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[graph_partition]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_allow_flexible_layouts]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[run_jit_post_compile_hook]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_embedding_bag_byte_unpack]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[loop_ordering_after_fusion]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[deterministic]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [eyt4i73byifiidlcgmugo4juf3sqznr7bv6k2xujnk6hfzd7vcn] inductor_config[small_memory_access_threshold]: 16777216
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[log_tlparse]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_dynamic_shapes]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[expand_dimension_for_pointwise_nodes]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [c2gaopsp6oqinpzvhlaz4gsqnq3shl5e54b7j6dsgwjadh5uatx] inductor_config[file_lock_timeout]: 600
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[torchinductor_worker_logpath]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.use_constexpr_for_int_array]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 8
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_or_error]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_template_tma_store]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.enable_epilogue_subtiling]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_pdl]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.dynamic_linkage]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_constants_on_disk_format]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.embed_kernel_binary]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.emit_multi_arch_kernel]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.link_libtorch]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.cross_target_platform]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.aoti_shim_library]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.aoti_shim_library_path]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor_mode.compile_standalone]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.contiguous_threshold]: 16
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[write_are_deterministic_algorithms_enabled]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_shape_assert]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.track_memory_lifecycle]: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.use_libtorch]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.aten_fx_overlap_scheduling]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[test_configs.aten_fx_overlap_insert_overlap_deps]: True
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.aten_fx_overlap_preserving_bucketing]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[test_configs.estimate_aten_runtime]: default
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_filter_reduction_configs]: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[test_configs.distort_benchmarking_result]: 
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)
[rank0]:V1015 13:43:39.578000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _custom_partitioner_fn: None
[rank0]:V1015 13:43:39.579000 4148767 torch/_inductor/compile_fx.py:919] [0/0] FX cache key generated: frlw45brionirhnoxrfjs5td5al4k5x5jtbtkx4adru4kflp3eho
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] Output code: 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] # AOT ID: ['0_forward']
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import torch
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import math
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import random
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import os
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import tempfile
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from math import inf, nan
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from cmath import nanj
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch import device, empty_strided
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] aten = torch.ops.aten
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] inductor_ops = torch.ops.inductor
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] _quantized = torch.ops._quantized
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] async_compile = AsyncCompile()
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] async_compile.wait(globals())
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] del async_compile
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] class Runner:
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     def __init__(self, partitions):
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         self.partitions = partitions
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     def recursively_apply_fns(self, fns):
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         new_callables = []
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         for fn, c in zip(fns, self.partitions):
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             new_callables.append(fn(c))
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         self.partitions = new_callables
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     def call(self, args):
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         primals_1, primals_2 = args
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         args.clear()
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         assert_size_stride(primals_1, (1, 8), (8, 1))
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         assert_size_stride(primals_2, (1, 32), (32, 1))
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         with torch.cuda._DeviceGuard(0):
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             torch.cuda.set_device(0)
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             # Topologically Sorted Source Nodes: [mm], Original ATen: [_c10d_functional.all_gather_into_tensor]
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             buf0 = torch.ops._c10d_functional.all_gather_into_tensor.default(primals_2, 8, '0')
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             assert_size_stride(buf0, (8, 32), (32, 1), 'torch.ops._c10d_functional.all_gather_into_tensor.default')
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             assert_alignment(buf0, 16, 'torch.ops._c10d_functional.all_gather_into_tensor.default')
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             # Topologically Sorted Source Nodes: [mm], Original ATen: [_c10d_functional.wait_tensor]
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             torch.ops._c10d_functional.wait_tensor.default(buf0)
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             del primals_2
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             buf3 = empty_strided_cuda((1, 32), (32, 1), torch.float32)
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             # Topologically Sorted Source Nodes: [mm], Original ATen: [aten.mm]
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             extern_kernels.mm(primals_1, buf0, out=buf3)
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             del buf0
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         return (buf3, reinterpret_tensor(primals_1, (8, 1), (1, 8), 0), )
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] runner = Runner(partitions=[])
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] call = runner.call
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] recursively_apply_fns = runner.recursively_apply_fns
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     from torch._inductor.utils import print_performance
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     primals_1 = rand_strided((1, 8), (8, 1), device='cuda:0', dtype=torch.float32)
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     primals_2 = rand_strided((1, 32), (32, 1), device='cuda:0', dtype=torch.float32)
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     fn = lambda: call([primals_1, primals_2])
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] if __name__ == "__main__":
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1258] [0/0] [__output_code] Output code written to: /tmp/torchinductor_pianpwk/ih/cihdis3g2mudkhxpatrpioun3xph5voykmwgnvijgpl6jufzws2u.py
[rank0]:I1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1576] [0/0] fx graph cache hit for key frlw45brionirhnoxrfjs5td5al4k5x5jtbtkx4adru4kflp3eho
[rank0]:I1015 13:43:39.595000 4148767 torch/_inductor/codecache.py:1015] [0/0] Increasing NCCL timeout by 0
[rank0]:V1015 13:43:39.595000 4148767 torch/_inductor/compile_fx.py:1026] [0/0] FX cache hit with key: frlw45brionirhnoxrfjs5td5al4k5x5jtbtkx4adru4kflp3eho
[rank0]:V1015 13:43:39.596000 4148767 torch/_inductor/compile_fx.py:1079] [0/0] FX codegen and compilation took 0.024s
[rank0]:I1015 13:43:39.596000 4148767 torch/_inductor/compile_fx.py:1106] [0/0] Overview info of inductor aten mms: 
[rank0]:I1015 13:43:39.596000 4148767 torch/_inductor/compile_fx.py:1107] [0/0] Name                           | B                    | M                    | N                    | K                    | Count               
[rank0]:I1015 13:43:39.596000 4148767 torch/_inductor/compile_fx.py:1112] [0/0] ----------------------------------------------------------------------------------------------------------------------------------
[rank0]:I1015 13:43:39.596000 4148767 torch/_inductor/compile_fx.py:1121] [0/0] Step 3: torchinductor done compiling FORWARDS graph 0
[rank0]:I1015 13:43:39.599000 4148767 torch/_dynamo/output_graph.py:2343] [0/0] Step 2: done compiler function inductor
[rank0]:I1015 13:43:39.602000 4148767 torch/fx/experimental/symbolic_shapes.py:5297] [0/0] produce_guards
[rank0]:V1015 13:43:39.602000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.size()[0] 1 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.size()[1] 8 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.stride()[0] 8 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.stride()[1] 1 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.storage_offset() 0 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x'].size()[0] 8 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x'].size()[1] 8 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x'].stride()[0] 8 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x'].stride()[1] 1 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x'].storage_offset() 0 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.size()[0] 1 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.size()[1] 8 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.stride()[0] 8 None
[rank0]:V1015 13:43:39.603000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.stride()[1] 1 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.storage_offset() 0 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.size()[0] 1 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.size()[1] 8 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.stride()[0] 8 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.stride()[1] 1 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor.storage_offset() 0 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor._base.size()[0] 1 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor._base.size()[1] 8 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor._base.stride()[0] 8 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor._base.stride()[1] 1 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['x']._local_tensor._base.storage_offset() 0 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.size()[0] 1 None
[rank0]:V1015 13:43:39.604000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.size()[1] 32 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.stride()[0] 32 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.stride()[1] 1 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.storage_offset() 0 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y'].size()[0] 8 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y'].size()[1] 32 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y'].stride()[0] 32 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y'].stride()[1] 1 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y'].storage_offset() 0 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.size()[0] 1 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.size()[1] 32 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.stride()[0] 32 None
[rank0]:V1015 13:43:39.605000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.stride()[1] 1 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.storage_offset() 0 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.size()[0] 1 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.size()[1] 32 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.stride()[0] 32 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.stride()[1] 1 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor.storage_offset() 0 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor._base.size()[0] 1 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor._base.size()[1] 32 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor._base.stride()[0] 32 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor._base.stride()[1] 1 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5523] [0/0] track_symint L['y']._local_tensor._base.storage_offset() 0 None
[rank0]:V1015 13:43:39.606000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.size()[0] == 1
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.size()[1] == 8
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.stride()[0] == 8
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.stride()[1] == 1
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.storage_offset() == 0
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x'].size()[0] == 8
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x'].size()[1] == 8
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x'].stride()[0] == 8
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x'].stride()[1] == 1
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x'].storage_offset() == 0
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.size()[0] == 1
[rank0]:V1015 13:43:39.607000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.size()[1] == 8
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.stride()[0] == 8
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.stride()[1] == 1
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.storage_offset() == 0
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.size()[0] == 1
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.size()[1] == 8
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.stride()[0] == 8
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.stride()[1] == 1
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor.storage_offset() == 0
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor._base.size()[0] == 1
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor._base.size()[1] == 8
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor._base.stride()[0] == 8
[rank0]:V1015 13:43:39.608000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor._base.stride()[1] == 1
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['x']._local_tensor._base.storage_offset() == 0
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.size()[0] == 1
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.size()[1] == 32
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.stride()[0] == 32
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.stride()[1] == 1
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.storage_offset() == 0
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y'].size()[0] == 8
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y'].size()[1] == 32
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y'].stride()[0] == 32
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y'].stride()[1] == 1
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y'].storage_offset() == 0
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.size()[0] == 1
[rank0]:V1015 13:43:39.609000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.size()[1] == 32
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.stride()[0] == 32
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.stride()[1] == 1
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.storage_offset() == 0
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.size()[0] == 1
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.size()[1] == 32
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.stride()[0] == 32
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.stride()[1] == 1
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor.storage_offset() == 0
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor._base.size()[0] == 1
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor._base.size()[1] == 32
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor._base.stride()[0] == 32
[rank0]:V1015 13:43:39.610000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor._base.stride()[1] == 1
[rank0]:V1015 13:43:39.611000 4148767 torch/fx/experimental/symbolic_shapes.py:5739] [0/0] Skipping guard L['y']._local_tensor._base.storage_offset() == 0
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3876] [0/0] [__guards] GUARDS:
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] 
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] TREE_GUARD_MANAGER:
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] +- RootGuardManager
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo/output_graph.py:802 in init_ambient_guards
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:790 in init_ambient_guards
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | +- GLOBAL_STATE: ___check_global_state()
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=<class 'torch.distributed.tensor.DTensor'>, tag_safe=(False, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- TYPE_MATCH: ___check_type_id(L['x'], 98776624)                            # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- LAMBDA_GUARD: ___check_metadata_140659999819808_c0/0                        # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- TENSOR_MATCH: check_tensor(L['x'], DTensor, DispatchKeySet(CUDA, BackendSelect, Python, ADInplaceOrView, AutogradCUDA, PythonTLSSnapshot), torch.float32, device=0, requires_grad=False, size=[8, 8], stride=[8, 1])  # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['x'], L['y'], L['x']._local_tensor, L['y']._local_tensor)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- GuardManager: source=L['x']._local_tensor, accessed_by=GetAttrGuardAccessor(_local_tensor), type=<class 'torch.Tensor'>, tag_safe=(True, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- TENSOR_MATCH: check_tensor(L['x']._local_tensor, Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=False, size=[1, 8], stride=[8, 1])  # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- NO_HASATTR: hasattr(L['x']._local_tensor, '_dynamo_dynamic_indices') == False  # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- NO_TENSOR_ALIASING
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- GuardManager: source=L['x'].__tensor_flatten__()[0], accessed_by=PythonLambdaGuardAccessor, type=<class 'list'>, tag_safe=(False, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- EQUALS_MATCH: L['x'].__tensor_flatten__()[0] == ['_local_tensor']           # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | +- GuardManager: source=L['y'], accessed_by=FrameLocalsGuardAccessor(key='y', framelocals_idx=1), type=<class 'torch.distributed.tensor.DTensor'>, tag_safe=(False, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- TYPE_MATCH: ___check_type_id(L['y'], 98776624)                            # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- LAMBDA_GUARD: ___check_metadata_140659999820528_c0/0                        # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- TENSOR_MATCH: check_tensor(L['y'], DTensor, DispatchKeySet(CUDA, BackendSelect, Python, ADInplaceOrView, AutogradCUDA, PythonTLSSnapshot), torch.float32, device=0, requires_grad=True, size=[8, 32], stride=[32, 1])  # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- NO_HASATTR: hasattr(L['y'], '_dynamo_dynamic_indices') == False           # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- NO_TENSOR_ALIASING
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- GuardManager: source=L['y']._local_tensor, accessed_by=GetAttrGuardAccessor(_local_tensor), type=<class 'torch.Tensor'>, tag_safe=(True, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- TENSOR_MATCH: check_tensor(L['y']._local_tensor, Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=True, size=[1, 32], stride=[32, 1])  # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- NO_HASATTR: hasattr(L['y']._local_tensor, '_dynamo_dynamic_indices') == False  # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- NO_TENSOR_ALIASING
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- GuardManager: source=L['y'].__tensor_flatten__()[0], accessed_by=PythonLambdaGuardAccessor, type=<class 'list'>, tag_safe=(False, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- EQUALS_MATCH: L['y'].__tensor_flatten__()[0] == ['_local_tensor']           # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | +- GuardManager: source=G, accessed_by=GlobalsGuardAccessor, type=<class 'dict'>, tag_safe=(False, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | +- GuardManager: source=G['torch'], accessed_by=DictGetItemGuardAccessor('torch'), type=<class 'module'>, tag_safe=(False, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- ID_MATCH: ___check_obj_id(G['torch'], 140664791820512)                  # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | +- GuardManager: source=G['torch'].mm, accessed_by=GetAttrGuardAccessor(mm), type=<class 'builtin_function_or_method'>, tag_safe=(True, False)
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] | | | | +- ID_MATCH: ___check_obj_id(G['torch'].mm, 140664659620016)               # return torch.mm(x, y)  # test/distributed/tensor/debug/test_debug_mode.py:575 in fn
[rank0]:V1015 13:43:39.611000 4148767 torch/_dynamo/guards.py:3590] [0/0] [__guards] 
[rank0]:V1015 13:43:39.622000 4148767 torch/_dynamo/guards.py:3622] [0/0] [__guards] Guard eval latency = 97.88 us
[rank0]:I1015 13:43:39.623000 4148767 torch/_dynamo/pgo.py:901] [0/0] put_code_state: no cache key, skipping
[rank0]:I1015 13:43:39.623000 4148767 torch/_dynamo/convert_frame.py:1654] [0/0] run_gc_after_compile: running gc
[rank0]:V1015 13:43:39.625000 4148767 torch/_dynamo/convert_frame.py:1981] skipping: inner (reason: in skipfiles, file: /data/users/pianpwk/pytorch/torch/_compile.py)
[rank0]:V1015 13:43:39.626000 4148767 torch/_dynamo/convert_frame.py:1981] skipping: disable (reason: in skipfiles, file: /data/users/pianpwk/pytorch/torch/_dynamo/decorators.py)
[rank0]:V1015 13:43:39.626000 4148767 torch/_dynamo/convert_frame.py:1981] skipping: innermost_fn (reason: in skipfiles, file: /data/users/pianpwk/pytorch/torch/_dynamo/eval_frame.py)
[rank0]:V1015 13:43:39.626000 4148767 torch/_dynamo/convert_frame.py:1981] skipping: __init__ (reason: in skipfiles, file: /data/users/pianpwk/pytorch/torch/_dynamo/eval_frame.py)
[rank0]:V1015 13:43:39.626000 4148767 torch/_dynamo/convert_frame.py:1981] skipping: __init__ (reason: in skipfiles, file: /data/users/pianpwk/pytorch/torch/_dynamo/eval_frame.py)
[rank0]:V1015 13:43:39.626000 4148767 torch/_dynamo/convert_frame.py:1981] skipping: nothing (reason: in skipfiles, file: /data/users/pianpwk/pytorch/torch/_dynamo/eval_frame.py)
[rank0]:V1015 13:43:39.626000 4148767 torch/_dynamo/convert_frame.py:1981] skipping: __call__ (reason: in skipfiles, file: /data/users/pianpwk/pytorch/torch/_dynamo/eval_frame.py)
[rank0]:V1015 13:43:39.627000 4148767 torch/_dynamo/convert_frame.py:1981] skipping: _fn (reason: in skipfiles, file: /data/users/pianpwk/pytorch/torch/_dynamo/eval_frame.py)
[rank0]:V1015 13:43:39.709000 4148767 torch/_inductor/compile_fx.py:883] [0/0] FX cache status: use_cache=True, local=True, remote=False, aot_mode=False, force_disable_caches=False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] FX graph cache hash details for key fb5m5acurexw7jmz7phibggkl6a3pkhdi3zg2ayvet2s6inf3j2x:
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [xxcde2rbdkfdcmfcqelfur3vvdu3fmyshxsttrs7k52bm6isuwo] gm: GraphModule()
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] def forward(self, permute, tangents_1):
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0]     mm_1 = torch.ops.aten.mm.default(permute, tangents_1);  permute = tangents_1 = None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0]     return (None, mm_1)
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0]     
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] # To see more debug info, please use `graph_module.print_readable()`
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ft4bo5vjvtra6lh6brp3mglfw35fgp2esqp2x5wbo5mk44bekjd] example_inputs[0]: TensorMetadata(dtype=torch.float32, shape=torch.Size([8, 1]), stride=(1, 8), device=device(type='cuda', index=0), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=32, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [twrt7dztsuqw6xffr3c4vdvwseclkp2od2nfidfqyapsj6z2lqe] example_inputs[1]: TensorMetadata(dtype=torch.float32, shape=torch.Size([1, 32]), stride=(32, 1), device=device(type='cuda', index=0), layout=torch.strided, memory_format=torch.contiguous_format, storage_offset=0, storage_bytes=None, requires_grad=False, is_quantized=False, is_conj=False, is_neg=False, is_inference=False, is_sparse=False, is_coalesced=None, dense_dim=None, sparse_dim=None)
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] cache_key_tag: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [lmglpn4zi7vob56n34r2j2rk7flv5xfgrcvmo7xcpirqsitygqx] fx_kwargs[boxed_forward_device_index]: BoxedDeviceIndex(value=None)
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[cpp_wrapper]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [xq2hdkbfkbcuye6rgtypayrkhqf4cntij2dsd24rei3lsknakkf] fx_kwargs[cudagraphs]: BoxedBool(value=False)
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[extern_node_serializer]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[fx_wrapper]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] fx_kwargs[is_backward]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] fx_kwargs[is_inference]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] fx_kwargs[layout_opt]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [reylvtt3rqfvzq5b3fjekfvick4dxsjoog5svxckgogwqosgp6z] fx_kwargs[static_input_idxs]: [0]
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inputs_to_check[0]: 1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [du4vyrfyozrfxcf6kk6ma7oqwatapifazeelfsawmsiu6gjdtxp] deterministic_algorithms_settings: (False, False, True)
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [pyawus3dzq5k52f53obyevhjmttghvob2hr5d7g4uml5s7av6wb] cuda_matmul_settings: ('none', True, True)
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [kf4pkt4tzlxrqjlyx7qoq54jgkkbevnea23xjd2e7ocd2ssq2uy] torch_version: ��B|�#�l�f�^X�nh���t�9TN�'�ʙZ
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [poglqjwowp4gnkmehjby2lvdjrwuo5tbxa2gayd6smgasl2hgsd] system_info[device]: {'name': 'NVIDIA H100'}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [gmdy3xpmssv2cijclukk43v25pzgfxwpb6e4z4sfiwmaelle6i5] system_info[version]: {'triton': '3.5.00355c3e3452fa4500122244b8fff8864f22bc05c417a3d6f5dada9f2e92f8040-c4d799c32eb6a3b92ad36ad7ea5645efc5b2fc6cd5c73dadc3a678d57dd2ccf4-c37149275a03d063fc1c339cd76a19da1c17e3d555410372e6cad29eedef6202-23d635e690d670bf61798e1259674b78c0ed5ba222ab6a455f329f27a758fc2d-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-03bffcc16c9d6be5ea8fde645caf3a6e3c0ac892eec49051a79d4cc99b66b9c7-e68505098eef3e7c0b050cb91da2587ab6c10d455ca0b941ff06fa8068e16305-318dbf7101b6ea9ebccfc57046fd8d963fe1d837c487005b37edf471a3207a9d-25cb0bee9547488335de2d495af738298ba6d4c20f1d37941dc17751c57a211e-e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855-3e3d33fbab70c7c05fc70e2e2fdd763dca0b847f62150592b99f8886a419ee64-83ef58f2371da7ad8e01822c2afc82f9a2d6516c2249ee0bbd8873bb20616be0-428d70cb058f1fffef47a6dbcc0be1a84551011aa2203dd5a6a613a6180e9c2f-5c1281b67c0d949da34ccf1c3b68804a2caa2665953984d837d753e91af611fe-5d15c5bebef8d7aa51b21fd187e5faa95eba4a213254355bc69e0648013599f7-30106ed84518c6ca7aca08e2c0ee188755f512cc0cb2d7da8914cc48c1ad6dcc-adb54e71d0ffc3bdac437fbc97929769fbbe4ebd03e6361c6357f2a24f7c5954-27b2a5d1e8db008bacefe6019f63922bbd65926de90bb1b527ee597477d2f365-a610dc5c215589aab7a784e1c07acef3e16d53ef00f08de793899964956f4e2a-18572e33e474a820799036f2b2f8c3e54d8a526386356716cccf2bf32a832376-2cdca74c4297804dcf499a7e9d4315ab87edfe2d72f536a8fdc02f28a3e7dacd-b53abe93473eb37d88bc378692065c9a8b1bf54b6417cb1911a13d10918c6d20-f60c2bb2d8eebe1c191f4b8b819844414dd1bce243645635a094f9f92665a58e-08abee21ce6230a873ed0831f70f9570b7ce39969dbf9b2f28ae1a1992ee1cc7-8e4b8599f819f32bcabae6fd118dbbccfbec0ba9e1909224d39c5fe32fbb491f-3db4bee9427c7eb0e2105aff484bdacc819357d298e8f6e89c372ae9c3625bdf-59cf295f3aab4fa62b96a627aa9fec1302950133750de59e542c7b4c9e5b80b6-5305890c3b133def44e2f3d3405e0fb1fd6ce78d0a28b2127670a195bbe11c66', 'cuda': '12.4'}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4dqne2ki3ebfnda5zvbe7wpqn3aw5vd6zyzhi735zdflhcvrrc2] system_info[hash]: 453a6d85f75096fc411d286136956c3fec25ea7f8d879b9957960fb1eefe4d41
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[TYPE_CHECKING]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_padding]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[can_inplace_pad_graph_input]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_auto_functionalized_v2]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_progress]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[verbose_progress]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[worker_log_path]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [mxibia26nanvqq4lqvdfub66benrqh5fqtsyzzj2qnwy7srv2s3] inductor_config[precompilation_timeout_seconds]: 3600
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[remote_gemm_autotune_cache]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bundle_triton_into_fx_graph_cache]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[non_blocking_remote_cache_write]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bundled_autotune_remote_cache]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_skip_cache_dynamic_shape_guards]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[unsafe_marked_cacheable_functions]: {}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sleep_sec_TESTING_ONLY]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [pikr7bbcoixfzftsazp5ggufhdklj24babfry77bl4nuvyrrcp4] inductor_config[triton_kernel_default_layout_constraint]: needs_fixed_stride_order
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp_wrapper_build_separate]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fx_wrapper]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp_cache_precompile_headers]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[online_softmax]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[dce]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[static_weight_shapes]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[size_asserts]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[nan_asserts]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[scalar_asserts]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[alignment_asserts]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pick_loop_orders]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[inplace_buffers]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[allow_buffer_reuse]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[memory_planning]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[use_fast_math]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bfloat16_atomic_adds_enabled]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [x75won4jmsgeb63pcvwr2y4eteyzzdhmf5rv6xhjppie4hx2yu5] inductor_config[memory_pool]: intermediates
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_harness]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[epilogue_fusion]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[prologue_fusion]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[epilogue_fusion_first]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[pattern_matcher]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[b2b_gemm_pass]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[custom_partitioner_fn]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[pre_grad_custom_pass]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[_post_fusion_custom_pass]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_cat_fx_passes]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[efficient_conv_bn_eval_fx_passes]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[is_predispatch]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[group_fusion]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[batch_fusion]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[pre_grad_fusion_options]: {}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[post_grad_fusion_options]: {}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_locality]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[dynamic_scale_rblock]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_fuse_int_mm_with_mul]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_mixed_mm]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [zwmmbkdkarexuhbigurz5lfnhx64tht7fznecjkrvznh6rzivbv] inductor_config[fx_passes_numeric_check]: {'pre_grad': False, 'precision': 0.0001, 'num_iterations': 1, 'requires_optimizer': True}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v2td5s4lnsvyxvaevy4chx6kc5h3mm2axazbgwimqule5zrzao7] inductor_config[mixed_mm_choice]: heuristic
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_compute_comm_overlap]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ssupi7bu3rrhdpg2jyegzncu3kg3nnhklyliqvutaxgs7y7k3dx] inductor_config[reorder_for_compute_comm_overlap_passes]: ['reorder_compute_for_overlap', 'sink_waits', 'raise_comms']
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_prefetch_limit]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[reorder_for_peak_memory]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_for_peak_memory_debug]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[size_threshold_for_succ_based_strategy]: 0
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[reorder_iterative_debug_memory_recompute]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[env_str]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[reorder_iterative_debug_limit_to_reorder]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[sink_waits_iterative_debug_limit_to_sink]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_all_gathers_fx]: none
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_all_gathers_fx_bucket_size_determinator]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [t3u4yj5mzijyfjvypyqngc4gf3wv6433necbugezv54jsexzrfp] inductor_config[bucket_reduce_scatters_fx]: none
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[bucket_reduce_scatters_fx_bucket_size_determinator]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[estimate_op_runtime]: default
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[runtime_estimations_mms_benchmark]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [yezuzjtg4h3jjur4jwtwiehbyixa7eonq4tqsqmwqve2lvvmrem] inductor_config[intra_node_bw]: 300
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[inter_node_bw]: 25
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_experimental_benchmarker]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_pointwise]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_gemm]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[autotune_num_choices_displayed]: 10
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_report_choices_stats]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[max_autotune_prune_choices_based_on_shared_mem]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton_disable_device_detection]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[graph_partition]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[max_autotune_allow_flexible_layouts]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_same_precision]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[multi_kernel_hints]: []
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [2y7luesktjrque3nr7qtxnum2mkbeegzdrsvkm3rvdlhqboajhx] inductor_config[max_autotune_gemm_backends]: ATEN,TRITON,CPP
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [uqlsbif4zxd75vt522p52txyuguieipi2lwz5g5awt56lccqk7s] inductor_config[max_autotune_conv_backends]: ATEN,TRITON
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_gemm_search_space]: DEFAULT
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[max_autotune_flex_search_space]: DEFAULT
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_fallback_to_aten]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [wft6ljqsfr3x4m7fa5zuyb7cwknky4irrxz4bjr6uzr2yiopxqj] inductor_config[unbacked_symint_fallback]: 8192
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[search_autotune_cache]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[save_args]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_in_subproc]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [iglov24t7x5ruci344aer2tm6nqshi4veuw4wxlssxtu46cx76m] inductor_config[max_autotune_subproc_result_timeout_seconds]: 60.0
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_graceful_timeout_seconds]: 0.0
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [zslw6pp37dzmhi5lhweftlhhdttfjade3t5j3y3vfk3ouze7nhw] inductor_config[max_autotune_subproc_terminate_timeout_seconds]: 0.0
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[autotune_multi_device]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_tuning]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[coordinate_descent_check_all_directions]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[coordinate_descent_search_radius]: 1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[autoheuristic_collect]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [jwbrgxes7vjqumngs5hyj6gn5nytv2whnppnzngvaagfmawhkkd] inductor_config[autoheuristic_use]: mixed_mm
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[run_jit_post_compile_hook]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [jvchmi66fvqzlemhr5fcqorz5trfdtdalzfagtj2aolmimwqhdq] inductor_config[autoheuristic_log_path]: DEFAULT
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4p2fdjlvxrcw7c7fvzm5huhtqxnro4kvkx56f7p5zyrxqkwooov] inductor_config[layout_opt_default]: 1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[layout_optimization]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_layout_optimization]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[keep_output_stride]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[warn_mix_layout]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [lkkae3meylaixfif4thncru4hjqeaislawjoghffrbwuscaagei] inductor_config[realize_reads_threshold]: 4
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [rr5m5hsocoyodldz7vcvaizdwvm2rt34evmqdxvng7wz3tufvo6] inductor_config[realize_opcount_threshold]: 30
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[realize_acc_reads_threshold]: 8
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[realize_acc_reads_size_threshold]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_random]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[fallback_embedding_bag_byte_unpack]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[implicit_fallbacks]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_unaligned_fallback_output]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aggressive_fusion]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_fusion]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_fusion]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[enabled_metric_tables]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[loop_ordering_after_fusion]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[score_fusion_memory_threshold]: 10
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[benchmark_epilogue_fusion]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[max_epilogue_benchmarked_choices]: 1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_size]: 64
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [jykiys6ynafs3zdylwa5ggq6j655mxeh42d6mtdi22gffkrmiac] inductor_config[max_fusion_buffer_group_pairwise_attempts]: 64
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[max_pointwise_cat_inputs]: 8
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_pointwise_cat]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[unroll_reductions_threshold]: 8
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[comment_origin]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[conv_1x1_as_mm]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[split_reductions]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[deterministic]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[min_num_split]: 0
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_kernel]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[constant_and_index_propagation]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[always_keep_tensor_constants]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[assert_indirect_indexing]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[compute_all_bounds]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[combo_kernels]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[benchmark_combo_kernel]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernels_autotune]: 1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[combo_kernel_allow_mixed_sizes]: 1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[combo_kernel_foreach_dynamic_shapes]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[joint_graph_constant_folding]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_index_asserts]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[emulate_precision_casts]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[is_nightly_or_source]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[developer_warnings]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[optimize_scatter_upon_const_tensor]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[add_pre_grad_passes]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[remove_pre_grad_passes]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [eyt4i73byifiidlcgmugo4juf3sqznr7bv6k2xujnk6hfzd7vcn] inductor_config[small_memory_access_threshold]: 16777216
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[worker_suppress_logging]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[log_tlparse]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_fuse_ddp_communication]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [5fxczt3ciyxitdhizb7sfsgn7fhpczcqsngttnt5ot2wyctk7co] inductor_config[_fuse_ddp_bucket_size]: 25
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_micro_pipeline_tp]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_collective.auto_select]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4vdewewvaarnygruqwzavmkvu4lqggolypo2tq5ohtx2kcelkky] inductor_config[_collective.one_shot_all_reduce_threshold_bytes]: 131072
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[quiesce_async_compile_pool]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[use_static_cuda_launcher]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[static_launch_user_defined_triton_kernels]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[strict_static_cuda_launcher]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[global_cache_dir]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[kernel_name_max_ops]: 10
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[shape_padding]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[comprehensive_padding]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_channels_last]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_dynamic_shapes]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[disable_padding_cpu]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[expand_dimension_for_pointwise_nodes]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[padding_alignment_bytes]: 128
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [dnnw5ks3yxrp7mwvihb2hh4tqx35ye637xt33x64kw4fvz2nyzg] inductor_config[padding_stride_threshold]: 1024
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[pad_outputs]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[bw_outputs_user_visible]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[force_shape_pad]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[permute_fusion]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profiler_mark_wrapper_call]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[generate_intermediate_hooks]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[debug_ir_traceback]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[_raise_error_for_testing]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[_profile_var]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[profile_bandwidth_regex]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[profile_bandwidth_output]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[profile_bandwidth_with_do_bench_using_profiling]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[disable_cpp_codegen]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[freezing_discard_parameters]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[decompose_mem_bound_mm]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[assume_aligned_inputs]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[unsafe_ignore_unsupported_triton_autotune_args]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[check_stack_no_cycles_TESTING_ONLY]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[enable_linear_binary_folding]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[annotate_training]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[enable_caching_generated_triton_templates]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[autotune_lookup_table]: {}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [c2gaopsp6oqinpzvhlaz4gsqnq3shl5e54b7j6dsgwjadh5uatx] inductor_config[file_lock_timeout]: 600
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[torchinductor_worker_logpath]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [sz3im5ogc6asp7g4uqocnovype63tkdexzfrniv6hn2oank3biu] inductor_config[cpp.threads]: -1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.no_redundant_loops]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.dynamic_threads]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.simdlen]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [xgnfe6mw7nii5zpxhlblgsehzrcqmjqpqswcwvf5adwbhz7aj2h] inductor_config[cpp.min_chunk_size]: 512
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [c7zj4qytmety6keurs3hsh5wn7foxp3dqx4kym2ucszzcb2ngrf] inductor_config[cpp.cxx]: (None, 'g++')
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_kernel_profile]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.weight_prepack]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_relu_bug_TESTING_ONLY]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.inject_log1p_bug_TESTING_ONLY]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.vec_isa_ok]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[cpp.descriptive_names]: original_aten
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[cpp.max_horizontal_fusion_size]: 16
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.fallback_scatter_reduce_sum]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_unsafe_math_opt_flag]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ijs44lspkinjvhcs7uff7n3noc53jvsp4yfljjh22mafhb7khxe] inductor_config[cpp.enable_floating_point_contract_flag]: off
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_tiling_heuristics]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_grouped_gemm_template]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cpp.gemm_max_k_slices]: 1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_cache_blocking]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cpp.gemm_thread_factors]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.enable_loop_tail_vec]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.enable_concat_linear]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_decompose_tanh]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.use_small_dequant_buffer]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cpp.force_inline_kernel]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cpp.use_constexpr_for_int_array]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraphs]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_trees]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_skip_dynamic_graphs]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.cudagraph_capture_sizes]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.slow_path_cudagraph_asserts]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_trees_history_recording]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.cudagraph_support_input_mutation]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ljdqgtysl3vdf7j6attlz5gmjg2ncihnveojfyubosplmkrjgra] inductor_config[triton.cudagraph_unexpected_rerecord_limit]: 128
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [yttmfmxblgcbsvbokguzowcorrcxz5uunxtcvsbe6nijgcx45he] inductor_config[triton.cudagraph_dynamic_shape_warn_limit]: 8
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraph_sync]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cudagraphs_warmup]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cudagraph_or_error]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.fast_path_cudagraph_asserts]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_cudagraph_warmup]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_graph]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.debug_sync_kernel]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.dense_indexing]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.coalesce_tiling_analysis]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.max_tiles]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.prefer_nd_tiling]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_pointwise]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.autotune_cublasLt]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.autotune_at_compile_time]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.autotune_with_sample_inputs]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.tile_reductions]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_pointwise_fusion]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.tiling_prevents_reduction_fusion]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.unique_kernel_names]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.unique_user_kernel_names]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [yrty22bseefglnysuoec4ji7j2rnaggdj3g33zzj7avogwfmgdw] inductor_config[triton.descriptive_names]: original_aten
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.persistent_reductions]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.cooperative_reductions]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.force_cooperative_reductions]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [vrl5ktomgtzox5xucd3np6vug3vyj6hwwzahqijuwpmamlv7ohi] inductor_config[triton.multi_kernel]: 0
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.divisible_by_16]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [fv6slhtedtydps5s5u2etitscliblzcidyitqf7krsv4e23fzk6] inductor_config[triton.min_split_scan_rblock]: 256
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.store_cubin]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[triton.spill_threshold]: 16
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_block_ptr]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.use_tensor_descriptor]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[triton.inject_relu_bug_TESTING_ONLY]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.codegen_upcast_to_fp32]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_persistent_tma_matmul]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_template_tma_store]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[triton.enable_epilogue_subtiling]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.skip_l1_cache]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.disallow_failing_autotune_kernels_TESTING_ONLY]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [j6c55jha5r2sdys2rwq7uqhtleea5dgjcye7nicfgft36v7xfvp] inductor_config[triton.num_decompose_k_splits]: 10
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [jffvide67gguonizth6bla7qwy6egn73yfn66335sv5b7i2rx3p] inductor_config[triton.decompose_k_threshold]: 32
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[triton.enable_pdl]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.output_path]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.debug_compile]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [6fxyf5ymh244xdypwkhtsbszab4nnfsgmul2kmyqmw422i5h54e] inductor_config[aot_inductor.compile_wrapper_opt_level]: O1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[aot_inductor.debug_intermediate_value_printer]: 0
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.filtered_kernel_names]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_in_spec]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[aot_inductor.serialized_out_spec]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_runtime_constant_folding]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.force_mmap_weights]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.use_consts_asm_build]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.package]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_cpp_only]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.dynamic_linkage]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.metadata]: {}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.raise_error_on_ignored_optimization]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.dump_aoti_minifier]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [pr5nr4a7dthirgd2ljo3d2xakc63ywxugusu6mkmr6gmpeliyib] inductor_config[aot_inductor.repro_level]: 2
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.presets]: {}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.allow_stack_allocation]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.use_minimal_arrayref_interface]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.weight_use_caching_allocator]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.package_constants_in_so]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.package_constants_on_disk_format]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.precompile_headers]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.embed_kernel_binary]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.emit_multi_arch_kernel]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.model_name_for_generated_files]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [4bryyl4ahh5whyg3zwqebpwmjnx6w77nqgqbdjlowju6lkqtn7w] inductor_config[aot_inductor.custom_ops_to_c_shims]: {}
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.custom_op_libs]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor.enable_lto]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[aot_inductor.link_libtorch]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.cross_target_platform]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.aoti_shim_library]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[aot_inductor.aoti_shim_library_path]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[aot_inductor_mode.compile_standalone]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.arch]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.version]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tvyftmtdmezlejo2xllu7awzv4pzc4vm4fub4b3gpl5jptjkosi] inductor_config[cuda.compile_opt_level]: -O1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_cuda_lto]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_ptxas_info]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.enable_debug_info]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.use_fast_math]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_max_profiling_configs]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ty4d7ntvjwumcgotd4j6w7bwokf5njhzmtvqvxa32jjub6k2ty2] inductor_config[cuda.cutlass_max_profiling_swizzle_options]: [1, 2, 4, 8]
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_epilogue_fusion_enabled]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_tma_only]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cuda_cxx]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [aghvyrrgwvxijco2pk5wzc3cgmmthrbmgxitiibxuuscxdwrjd3] inductor_config[cuda.cutlass_backend_min_gemm_size]: 1
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.generate_test_runner]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_allowlist_regex]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[cuda.cutlass_op_denylist_regex]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ngkkx5e6z7erl6da23zb2cmsctz4yvaqyameyg5hbqln4wrhh7x] inductor_config[cuda.cutlass_instantiation_level]: 0
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.cutlass_hash_with_compile_cmd]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.cutlass_prescreening]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ly46nlihymo3siersryfadlchkmxk6ohljz4l7vognsjg2qurpp] inductor_config[cuda.cutlass_enabled_ops]: all
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.use_binary_remote_cache]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.upload_to_binary_remote_cache]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[cuda.binary_remote_cache_force_write]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[cuda.enable_caching_codegen]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[rocm.arch]: []
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [gzctoy3drvth5kwqmdxb4tjn2picfdjsdu33nbniulhx5hsi3lv] inductor_config[rocm.ck_supported_arch]: ['gfx90a', 'gfx942', 'gfx950']
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [klfqjprnpfhcdurgvuikvc4rpd5ynkpk77toousr5h3u5roty6p] inductor_config[rocm.compile_opt_level]: -O2
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.is_debug]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.save_temps]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.use_fast_math]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[rocm.flush_denormals]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.print_kernel_resource_usage]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.rocm_home]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_dir]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.generate_test_runner]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.n_max_profiling_configs]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_max_profiling_configs]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.ck_tile_max_profiling_configs]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[rocm.use_preselected_instances]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[rocm.kBatch_sweep]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.split_k_threshold]: 16
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ebt2ncs4f5y7dn7btzi76mnouepvzad474tmp5iju4wiuumjl4s] inductor_config[rocm.contiguous_threshold]: 16
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [bsvfcwwoczx2rlkdz2eta6doujsymyihmi46hhwk6clrrvwcb6m] inductor_config[cpu_backend]: cpp
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [caw4ly2z672k6kjfahoxwpajp5idhhtrpgf3ma2clylcp7c7aid] inductor_config[cuda_backend]: triton
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [ljhgflgihidopsfsdcbqynv27nceykby3nutyd5jlcpq7n6e7l4] inductor_config[halide.cpu_target]: host
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [wx7vmsmrdpk5ue2txlywp3lj3faqmdjphs5fgg2ehzsyno7uovg] inductor_config[halide.gpu_target]: host-cuda
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [svgytlua5wcyeia7wq7e6zgh5tsueikrnzchmdmouvmkpfsc2zq] inductor_config[halide.scheduler_cuda]: Anderson2021
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [k5ogk6345jvklsnu7g2njqstiz2g6pm5wmqpgg3kasrmuqwjvl6] inductor_config[halide.scheduler_cpu]: Adams2019
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.asserts]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.debug]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[halide.scan_kernels]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [zwewsbwzgzypcnzixgl7ybbc4tk5kq36yeo267m422vyiuhdyiv] inductor_config[_save_config_ignore]: ['trace.upload_tar', 'joint_custom_pre_pass', 'joint_custom_post_pass', 'pre_grad_custom_pass', 'aot_inductor.repro_level', 'aot_inductor.dump_aoti_minifier', 'post_grad_custom_pre_pass', 'post_grad_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass']
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [6trwnwm4voevl4joplmkcssruwgd46kgqfejamut6kq662kstpd] inductor_config[_cache_config_ignore_prefix]: ['trace', 'cuda.cutlass_dir', 'worker_start_method', 'compile_threads', 'post_grad_custom_post_pass', 'post_grad_custom_pre_pass', 'joint_custom_pre_pass', 'joint_custom_post_pass', '_fuse_ddp_communication_passes', '_pre_fusion_custom_pass', 'always_complex_memory_overlap_TESTING_ONLY', 'fx_graph_cache', 'fx_graph_remote_cache', 'autotune_local_cache', 'autotune_remote_cache']
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [h25wqx6vliw4j5rtzzbv6latydxyei3deyg6v7wzvnzryfktuki] inductor_config[external_matmul]: []
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[write_are_deterministic_algorithms_enabled]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_extern_kernel_in_multi_template]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.max_mm_configs]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_dtype_assert]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.runtime_triton_shape_assert]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.static_cpp_dtype_assert]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_name_regex]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.autotune_choice_desc_regex]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.graphsafe_rng_func_ignores_fallback_random]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] inductor_config[test_configs.track_memory_lifecycle]: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.use_libtorch]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.aten_fx_overlap_scheduling]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [cev5uo2jlwdhw2uyzcm7vr6cl23azjfw437f5r5lskm7spucos6] inductor_config[test_configs.aten_fx_overlap_insert_overlap_deps]: True
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.aten_fx_overlap_preserving_bucketing]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [lxxtoqhcoepwfokeiibd575gnxo3uzwiv4hmpomlwkpzqz3qzsh] inductor_config[test_configs.estimate_aten_runtime]: default
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] inductor_config[test_configs.force_filter_reduction_configs]: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [v3hzzlv4tjgvp3pyhmzagjd25orl6n7nynoa7svlhhwk73b7u3c] inductor_config[test_configs.distort_benchmarking_result]: 
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_pre_pass: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [esstihe2nyydk4mhzpvox3qkajyu5y5t23hk3fi2me7jn75xi3o] precompile_enabled: False
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] post_grad_custom_post_pass: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_pre_pass: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] joint_custom_post_pass: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _pre_fusion_custom_pass: None
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [nk3qjerriqqc77fquy5nbegbf4gnlzzbxbtxwvyxvcdzt65xl2a] _fuse_ddp_communication_passes[0]: fuse_ddp_with_concat_op
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [t46i2lzpuxqpmemjedva3sub75arja6fqed4duz4kp2bb7d3sgc] _fuse_ddp_communication_passes[1]: schedule_comm_wait
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [74x2jtykapblkbwkh24fsfbwq4iejjkibyckoc2bmgj6llnf57s] custom_backend_passes: (None, None, None, None, None)
[rank0]:V1015 13:43:39.714000 4148767 torch/_inductor/codecache.py:990] [0/0] [tquy2we2efmowuj4wuqzcfcfdcrkzkzmwdae6hprj7fa64jpusq] _custom_partitioner_fn: None
[rank0]:V1015 13:43:39.715000 4148767 torch/_inductor/compile_fx.py:919] [0/0] FX cache key generated: fb5m5acurexw7jmz7phibggkl6a3pkhdi3zg2ayvet2s6inf3j2x
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] Output code: 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] # AOT ID: ['0_backward']
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import torch
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import math
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import random
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import os
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] import tempfile
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from math import inf, nan
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from cmath import nanj
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch import device, empty_strided
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] aten = torch.ops.aten
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] inductor_ops = torch.ops.inductor
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] _quantized = torch.ops._quantized
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] async_compile = AsyncCompile()
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] async_compile.wait(globals())
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] del async_compile
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] class Runner:
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     def __init__(self, partitions):
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         self.partitions = partitions
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     def recursively_apply_fns(self, fns):
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         new_callables = []
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         for fn, c in zip(fns, self.partitions):
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             new_callables.append(fn(c))
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         self.partitions = new_callables
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     def call(self, args):
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         permute, tangents_1 = args
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         args.clear()
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         assert_size_stride(permute, (8, 1), (1, 8))
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         assert_size_stride(tangents_1, (1, 32), (32, 1))
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         with torch.cuda._DeviceGuard(0):
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             torch.cuda.set_device(0)
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             buf0 = empty_strided_cuda((8, 32), (32, 1), torch.float32)
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             # Topologically Sorted Source Nodes: [], Original ATen: [aten.mm]
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             extern_kernels.mm(permute, tangents_1, out=buf0)
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             del permute
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]             del tangents_1
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]         return (None, buf0, )
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] runner = Runner(partitions=[])
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] call = runner.call
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] recursively_apply_fns = runner.recursively_apply_fns
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     from torch._inductor.utils import print_performance
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     permute = rand_strided((8, 1), (1, 8), device='cuda:0', dtype=torch.float32)
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     tangents_1 = rand_strided((1, 32), (32, 1), device='cuda:0', dtype=torch.float32)
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     fn = lambda: call([permute, tangents_1])
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] if __name__ == "__main__":
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1257] [0/0] [__output_code] 
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1258] [0/0] [__output_code] Output code written to: /tmp/torchinductor_pianpwk/ko/ckopmlabqxxo2ad53fvbrj2gt2bevxuoafbri4xcyaeodimi5ftu.py
[rank0]:I1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1576] [0/0] fx graph cache hit for key fb5m5acurexw7jmz7phibggkl6a3pkhdi3zg2ayvet2s6inf3j2x
[rank0]:I1015 13:43:39.716000 4148767 torch/_inductor/codecache.py:1015] [0/0] Increasing NCCL timeout by 0
[rank0]:V1015 13:43:39.716000 4148767 torch/_inductor/compile_fx.py:1026] [0/0] FX cache hit with key: fb5m5acurexw7jmz7phibggkl6a3pkhdi3zg2ayvet2s6inf3j2x
[rank0]:V1015 13:43:39.717000 4148767 torch/_inductor/compile_fx.py:1079] [0/0] FX codegen and compilation took 0.007s
[rank0]:I1015 13:43:39.717000 4148767 torch/_inductor/compile_fx.py:1106] [0/0] Overview info of inductor aten mms: 
[rank0]:I1015 13:43:39.717000 4148767 torch/_inductor/compile_fx.py:1107] [0/0] Name                           | B                    | M                    | N                    | K                    | Count               
[rank0]:I1015 13:43:39.717000 4148767 torch/_inductor/compile_fx.py:1112] [0/0] ----------------------------------------------------------------------------------------------------------------------------------
[rank0]:I1015 13:43:39.717000 4148767 torch/_inductor/compile_fx.py:1121] [0/0] Step 3: torchinductor done compiling BACKWARDS graph 0
[rank0]:I1015 13:43:39.717000 4148767 torch/fx/experimental/symbolic_shapes.py:5297] [0/0] produce_guards
.
----------------------------------------------------------------------
Ran 1 test in 2.304s

OK
    inductor_graph_call(
      inputs: (t: f32[1, 8], t: f32[1, 32])
      cache_key: frlw45brionirhnoxrfjs5td5al4k5x5jtbtkx4adru4kflp3eho
      fx_kwargs: {static_input_idxs=[], cudagraphs=BoxedBool(value=False), graph_id=0, is_inference=False, boxed_forward_device_index=BoxedDeviceIndex(value=None), is_backward=False, cpp_wrapper=False, fx_wrapper=False, layout_opt=None, extern_node_serializer=None}
      post_grad_graph:
        class GraphModule(torch.nn.Module):
            def forward(self, primals_1: "f32[1, 8][8, 1]cuda:0", primals_2: "f32[1, 32][32, 1]cuda:0"):
                 # File: /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py:575 in fn, code: return torch.mm(x, y)
                all_gather_into_tensor: "f32[8, 32][32, 1]cuda:0" = torch.ops._c10d_functional.all_gather_into_tensor.default(primals_2, 8, '0');  primals_2 = None
                wait_tensor: "f32[8, 32][32, 1]cuda:0" = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
                mm: "f32[1, 32][32, 1]cuda:0" = torch.ops.aten.mm.default(primals_1, wait_tensor);  wait_tensor = None
                permute: "f32[8, 1][1, 8]cuda:0" = torch.ops.aten.permute.default(primals_1, [1, 0]);  primals_1 = None
                return (mm, permute)
    )
      _c10d_functional::all_gather_into_tensor(t: f32[1, 32], 8, 0)
      _c10d_functional::wait_tensor(t: f32[8, 32])
      aten::mm.out(t: f32[1, 8], t: f32[8, 32], out=t: f32[1, 32])
  aten::sum(dt: f32[8, 32]| S(0))
    aten::sum(t: f32[1, 32])
  aten::ones_like(dt: f32[]| P, pin_memory=False, memory_format=torch.preserve_format)
    aten::ones_like(t: f32[], pin_memory=False, memory_format=torch.preserve_format)
  aten::expand(dt: f32[]| R, [8, 32])
    aten::expand(t: f32[], [8, 32])
    redistribute_input(t: f32[8, 32], trace: R->S(0))
      aten::split.Tensor(t: f32[8, 32], 1)
      aten::clone(t: f32[1, 32])
  aten::clone(dt: f32[8, 32]| S(0), memory_format=torch.contiguous_format)
    aten::clone(t: f32[1, 32], memory_format=torch.contiguous_format)
    profiler::_record_function_enter_new(backward._backward_impl (dynamo_timed))
    profiler::_record_function_enter_new(compile_fx.<locals>.bw_compiler (dynamo_timed))
    profiler::_record_function_exit._RecordFunction(ScriptObject <__torch__.torch.classes.profiler._RecordFunction>)
    profiler::_record_function_exit._RecordFunction(ScriptObject <__torch__.torch.classes.profiler._RecordFunction>)
    inductor_graph_call(
      inputs: (t: f32[8, 1], t: f32[1, 32])
      cache_key: fb5m5acurexw7jmz7phibggkl6a3pkhdi3zg2ayvet2s6inf3j2x
      fx_kwargs: {static_input_idxs=[0], cudagraphs=BoxedBool(value=False), is_backward=True, graph_id=0, boxed_forward_device_index=BoxedDeviceIndex(value=None), cpp_wrapper=False, fx_wrapper=False, is_inference=False, layout_opt=None, extern_node_serializer=None}
      post_grad_graph:
        class GraphModule(torch.nn.Module):
            def forward(self, permute: "f32[8, 1][1, 8]cuda:0", tangents_1: "f32[1, 32][32, 1]cuda:0"):
                 # File: /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py:575 in fn, code: return torch.mm(x, y)
                mm_1: "f32[8, 32][32, 1]cuda:0" = torch.ops.aten.mm.default(permute, tangents_1);  permute = tangents_1 = None
                return (None, mm_1)
    )
      aten::mm.out(t: f32[8, 1], t: f32[1, 32], out=t: f32[8, 32])
    redistribute_input(t: f32[8, 32], trace: P->S(0))
      _c10d_functional::reduce_scatter_tensor(t: f32[8, 32], sum, 8, 0)
      _c10d_functional::wait_tensor(t: f32[1, 32])
    aten::_to_copy(t: f32[1, 32], dtype=torch.float32, layout=torch.strided, device=cpu)
    aten::detach(t: f32[1, 32])
I1015 13:43:41.341000 4148767 torch/_inductor/remote_cache.py:428] Cache Metrics: None
I1015 13:43:41.341000 4148767 torch/_inductor/remote_cache.py:428] 
I1015 13:43:41.341000 4148767 torch/_dynamo/eval_frame.py:619] TorchDynamo attempted to trace the following frames: [
I1015 13:43:41.341000 4148767 torch/_dynamo/eval_frame.py:619]   * fn /data/users/pianpwk/pytorch/test/distributed/tensor/debug/test_debug_mode.py:573
I1015 13:43:41.341000 4148767 torch/_dynamo/eval_frame.py:619] ]
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] TorchDynamo compilation metrics:
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] Function                                Runtimes (s)
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] ------------------------------------  --------------
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] _compile.compile_inner                        1.6675
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] compile_attempt_0                             1.643
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] bytecode_tracing                              0.0724
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] OutputGraph.call_user_compiler                1.5647
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] inductor_codecache_torch_key                  0.1086
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] _recursive_pre_grad_passes                    0.0029
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] create_aot_dispatcher_function                0.1939
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] aot_collect_metadata                          0.0098
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] aot_trace_joint_graph                         0.0206
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] _recursive_joint_graph_passes                 0.1207
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] pad_mm_benchmark                              0.0013
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] pad_mm_benchmark_get_do_bench                 0.0008
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] min_cut_rematerialization_partition           0.0108
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] compile_fx.<locals>.fw_compiler_base          0.0251
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] compile_fx_inner                              0.033
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] fx_codegen_and_compile                        0.0311
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] TritonBundler.read_and_emit                   0.0002
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] PyCodeCache.load_by_key_path                  0.0051
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] async_compile.wait                            0.0003
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] build_guards                                  0.0225
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] gc                                            0.0007
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] backward._backward_impl                       0.011
I1015 13:43:41.344000 4148767 torch/_dynamo/utils.py:850] compile_fx.<locals>.bw_compiler               0.0085
V1015 13:43:41.344000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats constrain_symbol_range: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.344000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats guard_or_defer_runtime_assert: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats _inner_evaluate_expr: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats _simplify_floor_div: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats _maybe_guard_rel: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats _find: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats has_hint: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats size_hint: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats simplify: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats _update_divisible: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats replace: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats _maybe_evaluate_static: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats get_implications: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats get_axioms: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats _maybe_evaluate_static_worker: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats safe_expand: CacheInfo(hits=0, misses=0, maxsize=256, currsize=0)
V1015 13:43:41.345000 4148767 torch/fx/experimental/symbolic_shapes.py:184] lru_cache_stats uninteresting_files: CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)
