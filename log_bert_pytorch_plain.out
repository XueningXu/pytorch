/data/users/pianpwk/pytorch/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
loading model: 0it [00:00, ?it/s]loading model: 0it [00:11, ?it/s]
cuda eval  BERT_pytorch                       
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_106", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.017791999503970146, "best_triton_pos": 0}
AUTOTUNE mm(512x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  triton_mm_106 0.0178 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_103 0.0179 ms 99.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_100 0.0185 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  mm 0.0192 ms 92.7% 
  triton_mm_102 0.0196 ms 90.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_99 0.0199 ms 89.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_105 0.0201 ms 88.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_101 0.0231 ms 76.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_98 0.0242 ms 73.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_mm_97 0.0262 ms 67.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.1987 seconds and 0.0005 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.022816000506281853, "best_triton_pos": 1, "best_triton_time": 0.03187200054526329, "best_triton_kernel": "triton_mm_1455", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8"}
AUTOTUNE mm(512x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  mm 0.0228 ms 100.0% 
  triton_mm_1455 0.0319 ms 71.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_mm_1458 0.0330 ms 69.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1452 0.0337 ms 67.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_mm_1460 0.0365 ms 62.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_1457 0.0374 ms 60.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_1450 0.0403 ms 56.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_1463 0.0414 ms 55.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1451 0.0471 ms 48.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_mm_1459 0.0491 ms 46.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.2429 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.011071999557316303, "best_triton_pos": 1, "best_triton_time": 0.012095999903976917, "best_triton_kernel": "triton_mm_83", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8"}
AUTOTUNE mm(512x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.0111 ms 100.0% 
  triton_mm_83 0.0121 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_mm_86 0.0127 ms 87.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_88 0.0131 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_85 0.0133 ms 83.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_78 0.0149 ms 74.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_79 0.0155 ms 71.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_mm_80 0.0157 ms 70.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_mm_91 0.0159 ms 69.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_87 0.0160 ms 69.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.1787 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "bmm", "best_time": 0.008960000239312649, "best_triton_pos": 1, "best_triton_time": 0.009088000282645226, "best_triton_kernel": "triton_bmm_41", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE bmm(24x256x64, 24x64x256)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  bmm 0.0090 ms 100.0% 
  triton_bmm_41 0.0091 ms 98.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_42 0.0091 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  triton_bmm_36 0.0093 ms 96.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_35 0.0097 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_43 0.0100 ms 89.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_46 0.0100 ms 89.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_47 0.0100 ms 89.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_45 0.0101 ms 88.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_34 0.0102 ms 87.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.1987 seconds and 0.0002 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 0.011168000288307667, "best_triton_pos": 1, "best_triton_time": 0.012160000391304493, "best_triton_kernel": "triton_bmm_65", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(24x256x256, 24x256x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 0.0112 ms 100.0% 
  triton_bmm_65 0.0122 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_64 0.0126 ms 88.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_70 0.0134 ms 83.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_71 0.0137 ms 81.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_72 0.0143 ms 78.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_69 0.0147 ms 76.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_bmm_73 0.0149 ms 74.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_66 0.0151 ms 73.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_74 0.0155 ms 72.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.1611 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_1474", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1", "best_time": 0.007007999811321497, "best_triton_pos": 0}
AUTOTUNE addmm(2x2, 2x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_1474 0.0070 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_1467 0.0072 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_1473 0.0072 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_1466 0.0077 ms 91.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_1470 0.0082 ms 85.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  triton_mm_1472 0.0088 ms 79.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_1465 0.0097 ms 72.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
  triton_mm_1471 0.0108 ms 64.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  addmm 0.0132 ms 53.2% 
  bias_addmm 0.0139 ms 50.5% 
SingleProcess AUTOTUNE benchmarking takes 0.1409 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_1486", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.09161599725484848, "best_triton_pos": 0}
AUTOTUNE addmm(512x20005, 512x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_1486 0.0916 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_1485 0.0938 ms 97.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1483 0.0943 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_1482 0.0956 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1489 0.1060 ms 86.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1488 0.1081 ms 84.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1480 0.1140 ms 80.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_1484 0.1150 ms 79.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1481 0.1166 ms 78.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_mm_1487 0.1474 ms 62.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.4247 seconds and 0.0002 seconds precompiling for 17 choices
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:00, 94.22it/s]running benchmark:  67%|██████▋   | 20/30 [00:00<00:00, 95.50it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 95.77it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 95.50it/s]
eager: 0.0071s, compiled: 0.0029s
HINT_SIZE (2, 256) RUNTIME_SIZE (2, 256) 2.490x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 54.21it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 54.35it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 54.29it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 54.26it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 54.32it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 54.28it/s]
eager: 0.0114s, compiled: 0.0065s
HINT_SIZE (2, 256) RUNTIME_SIZE (2, 1024) 1.742x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 18.80it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 18.85it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 18.87it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 18.85it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 18.85it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 18.85it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 18.85it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 18.85it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 18.86it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 18.85it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 18.86it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 18.85it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 18.85it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 18.85it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 18.85it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 18.85it/s]
eager: 0.0329s, compiled: 0.0195s
HINT_SIZE (2, 256) RUNTIME_SIZE (2, 2048) 1.690x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:00, 79.77it/s]running benchmark:  57%|█████▋    | 17/30 [00:00<00:00, 80.00it/s]running benchmark:  87%|████████▋ | 26/30 [00:00<00:00, 80.21it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 80.16it/s]
eager: 0.0078s, compiled: 0.0042s
HINT_SIZE (2, 256) RUNTIME_SIZE (8, 256) 1.844x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 16.19it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 16.13it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 16.12it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 16.10it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 16.10it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 16.07it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 16.06it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 16.07it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 16.06it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 16.07it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 16.08it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 16.09it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 16.08it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 16.08it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.08it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.08it/s]
eager: 0.0391s, compiled: 0.0223s
HINT_SIZE (2, 256) RUNTIME_SIZE (8, 1024) 1.750x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:05,  4.98it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:05,  4.97it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  4.97it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:05,  4.97it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:05,  4.97it/s]running benchmark:  20%|██        | 6/30 [00:01<00:04,  4.97it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  4.97it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  4.97it/s]running benchmark:  30%|███       | 9/30 [00:01<00:04,  4.97it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.97it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:03,  4.97it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  4.97it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  4.97it/s]running benchmark:  47%|████▋     | 14/30 [00:02<00:03,  4.97it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.97it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:02,  4.97it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  4.97it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  4.97it/s]running benchmark:  63%|██████▎   | 19/30 [00:03<00:02,  4.97it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.97it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:01,  4.97it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  4.97it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  4.97it/s]running benchmark:  80%|████████  | 24/30 [00:04<00:01,  4.97it/s]running benchmark:  83%|████████▎ | 25/30 [00:05<00:01,  4.97it/s]running benchmark:  87%|████████▋ | 26/30 [00:05<00:00,  4.97it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  4.97it/s]running benchmark:  93%|█████████▎| 28/30 [00:05<00:00,  4.97it/s]running benchmark:  97%|█████████▋| 29/30 [00:05<00:00,  4.97it/s]running benchmark: 100%|██████████| 30/30 [00:06<00:00,  4.97it/s]running benchmark: 100%|██████████| 30/30 [00:06<00:00,  4.97it/s]
eager: 0.1250s, compiled: 0.0747s
HINT_SIZE (2, 256) RUNTIME_SIZE (8, 2048) 1.674x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:00, 27.39it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 27.61it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 27.68it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 27.68it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 27.72it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 27.73it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 27.72it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 27.62it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 27.67it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.70it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.67it/s]
eager: 0.0209s, compiled: 0.0145s
HINT_SIZE (2, 256) RUNTIME_SIZE (32, 256) 1.439x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:06,  4.20it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.19it/s]running benchmark:  10%|█         | 3/30 [00:00<00:06,  4.19it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:06,  4.19it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:05,  4.19it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.19it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:05,  4.19it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:05,  4.19it/s]running benchmark:  30%|███       | 9/30 [00:02<00:05,  4.19it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.19it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.19it/s]running benchmark:  40%|████      | 12/30 [00:02<00:04,  4.19it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:04,  4.19it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.19it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.19it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.19it/s]running benchmark:  57%|█████▋    | 17/30 [00:04<00:03,  4.19it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:02,  4.19it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.19it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.19it/s]running benchmark:  70%|███████   | 21/30 [00:05<00:02,  4.19it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:01,  4.19it/s]running benchmark:  77%|███████▋  | 23/30 [00:05<00:01,  4.19it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.19it/s]running benchmark:  83%|████████▎ | 25/30 [00:05<00:01,  4.19it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:00,  4.19it/s]running benchmark:  90%|█████████ | 27/30 [00:06<00:00,  4.19it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.19it/s]running benchmark:  97%|█████████▋| 29/30 [00:06<00:00,  4.19it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.19it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.19it/s]
eager: 0.1527s, compiled: 0.0846s
HINT_SIZE (2, 256) RUNTIME_SIZE (32, 1024) 1.805x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:22,  1.27it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:22,  1.27it/s]running benchmark:  10%|█         | 3/30 [00:02<00:21,  1.27it/s]running benchmark:  13%|█▎        | 4/30 [00:03<00:20,  1.27it/s]running benchmark:  17%|█▋        | 5/30 [00:03<00:19,  1.27it/s]running benchmark:  20%|██        | 6/30 [00:04<00:18,  1.27it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:18,  1.27it/s]running benchmark:  27%|██▋       | 8/30 [00:06<00:17,  1.27it/s]running benchmark:  30%|███       | 9/30 [00:07<00:16,  1.27it/s]running benchmark:  33%|███▎      | 10/30 [00:07<00:15,  1.27it/s]running benchmark:  37%|███▋      | 11/30 [00:08<00:14,  1.27it/s]running benchmark:  40%|████      | 12/30 [00:09<00:14,  1.27it/s]running benchmark:  43%|████▎     | 13/30 [00:10<00:13,  1.27it/s]running benchmark:  47%|████▋     | 14/30 [00:11<00:12,  1.27it/s]running benchmark:  50%|█████     | 15/30 [00:11<00:11,  1.27it/s]running benchmark:  53%|█████▎    | 16/30 [00:12<00:11,  1.27it/s]running benchmark:  57%|█████▋    | 17/30 [00:13<00:10,  1.27it/s]running benchmark:  60%|██████    | 18/30 [00:14<00:09,  1.27it/s]running benchmark:  63%|██████▎   | 19/30 [00:14<00:08,  1.27it/s]running benchmark:  67%|██████▋   | 20/30 [00:15<00:07,  1.27it/s]running benchmark:  70%|███████   | 21/30 [00:16<00:07,  1.27it/s]running benchmark:  73%|███████▎  | 22/30 [00:17<00:06,  1.27it/s]running benchmark:  77%|███████▋  | 23/30 [00:18<00:05,  1.27it/s]running benchmark:  80%|████████  | 24/30 [00:18<00:04,  1.27it/s]running benchmark:  83%|████████▎ | 25/30 [00:19<00:03,  1.27it/s]running benchmark:  87%|████████▋ | 26/30 [00:20<00:03,  1.27it/s]running benchmark:  90%|█████████ | 27/30 [00:21<00:02,  1.27it/s]running benchmark:  93%|█████████▎| 28/30 [00:22<00:01,  1.27it/s]running benchmark:  97%|█████████▋| 29/30 [00:22<00:00,  1.27it/s]running benchmark: 100%|██████████| 30/30 [00:23<00:00,  1.27it/s]running benchmark: 100%|██████████| 30/30 [00:23<00:00,  1.27it/s]
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.036288000643253326, "best_triton_pos": 1, "best_triton_time": 0.04262400045990944, "best_triton_kernel": "triton_mm_1589", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(2048x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.0363 ms 100.0% 
  triton_mm_1589 0.0426 ms 85.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1592 0.0445 ms 81.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1595 0.0454 ms 79.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1593 0.0460 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_1596 0.0460 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1590 0.0467 ms 77.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_1587 0.0551 ms 65.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_1591 0.0553 ms 65.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1594 0.0573 ms 63.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.2810 seconds and 0.0004 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.04870399832725525, "best_triton_pos": 1, "best_triton_time": 0.05081599950790405, "best_triton_kernel": "triton_mm_2953", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(2048x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  mm 0.0487 ms 100.0% 
  triton_mm_2953 0.0508 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2947 0.0510 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_2950 0.0517 ms 94.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_2949 0.0602 ms 80.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2946 0.0604 ms 80.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2952 0.0623 ms 78.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2948 0.0658 ms 74.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2945 0.0722 ms 67.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_mm_2944 0.0856 ms 56.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.2839 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_1575", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.017152000218629837, "best_triton_pos": 0}
AUTOTUNE mm(2048x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  triton_mm_1575 0.0172 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_1578 0.0173 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  mm 0.0176 ms 97.5% 
  triton_mm_1581 0.0178 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1574 0.0188 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1577 0.0189 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1580 0.0196 ms 87.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1576 0.0224 ms 76.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_1573 0.0238 ms 72.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_mm_1572 0.0253 ms 67.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.1923 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "bmm", "best_time": 0.059039998799562454, "best_triton_pos": 1, "best_triton_time": 0.05926400050520897, "best_triton_kernel": "triton_bmm_1532", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4"}
AUTOTUNE bmm(24x1024x64, 24x64x1024)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  bmm 0.0590 ms 100.0% 
  triton_bmm_1532 0.0593 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  triton_bmm_1531 0.0596 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_1537 0.0669 ms 88.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_1535 0.0684 ms 86.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_1536 0.0732 ms 80.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_1526 0.0737 ms 80.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_1533 0.0743 ms 79.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_1525 0.0775 ms 76.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_1534 0.0790 ms 74.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.3437 seconds and 0.0002 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 0.0724480003118515, "best_triton_pos": 1, "best_triton_time": 0.07667200267314911, "best_triton_kernel": "triton_bmm_1555", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(24x1024x1024, 24x1024x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 0.0724 ms 100.0% 
  triton_bmm_1555 0.0767 ms 94.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_1554 0.0860 ms 84.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_1565 0.0906 ms 80.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_1558 0.0920 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_1564 0.0951 ms 76.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_1563 0.0957 ms 75.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_1562 0.0959 ms 75.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_1560 0.0962 ms 75.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_1559 0.0982 ms 73.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.2839 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_2964", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1", "best_time": 0.007040000054985285, "best_triton_pos": 0}
AUTOTUNE addmm(2x2, 2x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_2964 0.0070 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_2957 0.0071 ms 98.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_2963 0.0073 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_2956 0.0077 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_2960 0.0082 ms 86.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  triton_mm_2962 0.0088 ms 79.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_2955 0.0098 ms 72.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
  triton_mm_2961 0.0109 ms 64.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  addmm 0.0129 ms 54.6% 
  bias_addmm 0.0136 ms 51.6% 
SingleProcess AUTOTUNE benchmarking takes 0.1361 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_2975", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.30768001079559326, "best_triton_pos": 0}
AUTOTUNE addmm(2048x20005, 2048x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_2975 0.3077 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2976 0.3254 ms 94.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_2972 0.3284 ms 93.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2978 0.3385 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2973 0.3519 ms 87.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_2979 0.3636 ms 84.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2970 0.3809 ms 80.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_2974 0.4235 ms 72.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_2971 0.4450 ms 69.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  bias_addmm 0.5143 ms 59.8% 
SingleProcess AUTOTUNE benchmarking takes 0.6100 seconds and 0.0002 seconds precompiling for 17 choices
eager: 0.4930s, compiled: 0.2940s
HINT_SIZE (2, 256) RUNTIME_SIZE (32, 2048) 1.677x
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:00, 92.70it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 99.17it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 99.80it/s]
eager: 0.0069s, compiled: 0.0024s
HINT_SIZE (2, 1024) RUNTIME_SIZE (2, 256) 2.867x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 56.37it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 56.26it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 56.01it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 55.97it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 56.01it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 56.03it/s]
eager: 0.0113s, compiled: 0.0061s
HINT_SIZE (2, 1024) RUNTIME_SIZE (2, 1024) 1.849x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 19.72it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 19.77it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 19.81it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 19.82it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 19.82it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 19.83it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 19.83it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 19.82it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 19.83it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 19.82it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 19.81it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 19.82it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 19.83it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 19.83it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.82it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.82it/s]
eager: 0.0327s, compiled: 0.0172s
HINT_SIZE (2, 1024) RUNTIME_SIZE (2, 2048) 1.899x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 82.16it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 82.52it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 82.50it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 82.48it/s]
eager: 0.0075s, compiled: 0.0042s
HINT_SIZE (2, 1024) RUNTIME_SIZE (8, 256) 1.788x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 16.51it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 16.47it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 16.48it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 16.49it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 16.49it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 16.49it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 16.50it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 16.49it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 16.50it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 16.48it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 16.48it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 16.49it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 16.48it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 16.48it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.48it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.48it/s]
eager: 0.0388s, compiled: 0.0212s
HINT_SIZE (2, 1024) RUNTIME_SIZE (8, 1024) 1.828x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:05,  5.23it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:05,  5.21it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  5.21it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:04,  5.21it/s]running benchmark:  17%|█▋        | 5/30 [00:00<00:04,  5.21it/s]running benchmark:  20%|██        | 6/30 [00:01<00:04,  5.21it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  5.21it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  5.21it/s]running benchmark:  30%|███       | 9/30 [00:01<00:04,  5.21it/s]running benchmark:  33%|███▎      | 10/30 [00:01<00:03,  5.21it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:03,  5.21it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  5.21it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  5.21it/s]running benchmark:  47%|████▋     | 14/30 [00:02<00:03,  5.21it/s]running benchmark:  50%|█████     | 15/30 [00:02<00:02,  5.21it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:02,  5.21it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  5.21it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  5.21it/s]running benchmark:  63%|██████▎   | 19/30 [00:03<00:02,  5.21it/s]running benchmark:  67%|██████▋   | 20/30 [00:03<00:01,  5.21it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:01,  5.21it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  5.21it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  5.21it/s]running benchmark:  80%|████████  | 24/30 [00:04<00:01,  5.21it/s]running benchmark:  83%|████████▎ | 25/30 [00:04<00:00,  5.21it/s]running benchmark:  87%|████████▋ | 26/30 [00:04<00:00,  5.21it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  5.21it/s]running benchmark:  93%|█████████▎| 28/30 [00:05<00:00,  5.21it/s]running benchmark:  97%|█████████▋| 29/30 [00:05<00:00,  5.21it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.21it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.21it/s]
eager: 0.1248s, compiled: 0.0661s
HINT_SIZE (2, 1024) RUNTIME_SIZE (8, 2048) 1.887x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:00, 27.66it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 27.72it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 27.74it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 27.77it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 27.80it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 27.77it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 27.76it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 27.77it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 27.77it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.77it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.76it/s]
eager: 0.0208s, compiled: 0.0148s
HINT_SIZE (2, 1024) RUNTIME_SIZE (32, 256) 1.405x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:06,  4.25it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.24it/s]running benchmark:  10%|█         | 3/30 [00:00<00:06,  4.24it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:06,  4.24it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:05,  4.24it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.24it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:05,  4.23it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:05,  4.23it/s]running benchmark:  30%|███       | 9/30 [00:02<00:04,  4.23it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.24it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.23it/s]running benchmark:  40%|████      | 12/30 [00:02<00:04,  4.23it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:04,  4.23it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.23it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.23it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.23it/s]running benchmark:  57%|█████▋    | 17/30 [00:04<00:03,  4.23it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:02,  4.23it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.23it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.23it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:02,  4.23it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:01,  4.23it/s]running benchmark:  77%|███████▋  | 23/30 [00:05<00:01,  4.23it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.23it/s]running benchmark:  83%|████████▎ | 25/30 [00:05<00:01,  4.23it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:00,  4.23it/s]running benchmark:  90%|█████████ | 27/30 [00:06<00:00,  4.23it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.23it/s]running benchmark:  97%|█████████▋| 29/30 [00:06<00:00,  4.23it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.23it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.23it/s]
eager: 0.1525s, compiled: 0.0825s
HINT_SIZE (2, 1024) RUNTIME_SIZE (32, 1024) 1.848x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:22,  1.31it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:21,  1.32it/s]running benchmark:  10%|█         | 3/30 [00:02<00:20,  1.32it/s]running benchmark:  13%|█▎        | 4/30 [00:03<00:19,  1.32it/s]running benchmark:  17%|█▋        | 5/30 [00:03<00:18,  1.32it/s]running benchmark:  20%|██        | 6/30 [00:04<00:18,  1.32it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:17,  1.32it/s]running benchmark:  27%|██▋       | 8/30 [00:06<00:16,  1.32it/s]running benchmark:  30%|███       | 9/30 [00:06<00:15,  1.32it/s]running benchmark:  33%|███▎      | 10/30 [00:07<00:15,  1.32it/s]running benchmark:  37%|███▋      | 11/30 [00:08<00:14,  1.32it/s]running benchmark:  40%|████      | 12/30 [00:09<00:13,  1.32it/s]running benchmark:  43%|████▎     | 13/30 [00:09<00:12,  1.32it/s]running benchmark:  47%|████▋     | 14/30 [00:10<00:12,  1.32it/s]running benchmark:  50%|█████     | 15/30 [00:11<00:11,  1.32it/s]running benchmark:  53%|█████▎    | 16/30 [00:12<00:10,  1.32it/s]running benchmark:  57%|█████▋    | 17/30 [00:12<00:09,  1.32it/s]running benchmark:  60%|██████    | 18/30 [00:13<00:09,  1.32it/s]running benchmark:  63%|██████▎   | 19/30 [00:14<00:08,  1.32it/s]running benchmark:  67%|██████▋   | 20/30 [00:15<00:07,  1.32it/s]running benchmark:  70%|███████   | 21/30 [00:15<00:06,  1.32it/s]running benchmark:  73%|███████▎  | 22/30 [00:16<00:06,  1.32it/s]running benchmark:  77%|███████▋  | 23/30 [00:17<00:05,  1.32it/s]running benchmark:  80%|████████  | 24/30 [00:18<00:04,  1.32it/s]running benchmark:  83%|████████▎ | 25/30 [00:18<00:03,  1.32it/s]running benchmark:  87%|████████▋ | 26/30 [00:19<00:03,  1.32it/s]running benchmark:  90%|█████████ | 27/30 [00:20<00:02,  1.32it/s]running benchmark:  93%|█████████▎| 28/30 [00:21<00:01,  1.32it/s]running benchmark:  97%|█████████▋| 29/30 [00:22<00:00,  1.32it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.32it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.32it/s]
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.059039998799562454, "best_triton_pos": 1, "best_triton_time": 0.06985600292682648, "best_triton_kernel": "triton_mm_3085", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(4096x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.0590 ms 100.0% 
  triton_mm_3085 0.0699 ms 84.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_3079 0.0843 ms 70.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_3086 0.0850 ms 69.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_3082 0.0871 ms 67.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_3083 0.0883 ms 66.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_3084 0.0892 ms 66.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_3080 0.0904 ms 65.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_3081 0.0995 ms 59.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_3077 0.1075 ms 54.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.3845 seconds and 0.0005 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_4436", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.07135999947786331, "best_triton_pos": 0}
AUTOTUNE mm(4096x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  triton_mm_4436 0.0714 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4442 0.0745 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4439 0.0777 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  mm 0.0815 ms 87.6% 
  triton_mm_4443 0.0952 ms 75.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4440 0.0970 ms 73.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_4437 0.0975 ms 73.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_4438 0.0975 ms 73.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4434 0.0995 ms 71.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_4441 0.1028 ms 69.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.3681 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_3064", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.024800000712275505, "best_triton_pos": 0}
AUTOTUNE mm(4096x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  triton_mm_3064 0.0248 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_3067 0.0249 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_3070 0.0255 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  mm 0.0267 ms 93.0% 
  triton_mm_3062 0.0300 ms 82.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_3068 0.0306 ms 81.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_3065 0.0313 ms 79.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_3071 0.0326 ms 76.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_3069 0.0327 ms 75.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_3066 0.0333 ms 74.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.2224 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_bmm_3021", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.2011519968509674, "best_triton_pos": 0}
AUTOTUNE bmm(24x2048x64, 24x64x2048)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  triton_bmm_3021 0.2012 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_3022 0.2015 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  bmm 0.2122 ms 94.8% 
  triton_bmm_3023 0.2385 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_3016 0.2399 ms 83.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_3025 0.2403 ms 83.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_3027 0.2428 ms 82.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_3026 0.2484 ms 81.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_3015 0.2578 ms 78.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_3024 0.2634 ms 76.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 2.4369 seconds and 0.0002 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 0.23004800081253052, "best_triton_pos": 1, "best_triton_time": 0.24844799935817719, "best_triton_kernel": "triton_bmm_3045", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(24x2048x2048, 24x2048x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 0.2300 ms 100.0% 
  triton_bmm_3045 0.2484 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_3053 0.2529 ms 91.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_3054 0.2630 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_3056 0.2660 ms 86.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_3044 0.2792 ms 82.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_3055 0.2919 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_3048 0.3152 ms 73.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_3052 0.3160 ms 72.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_3050 0.3178 ms 72.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5359 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_4447", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1", "best_time": 0.006976000033318996, "best_triton_pos": 0}
AUTOTUNE addmm(2x2, 2x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_4447 0.0070 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_4454 0.0070 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_4453 0.0071 ms 98.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_4446 0.0077 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_4450 0.0081 ms 86.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  triton_mm_4452 0.0087 ms 79.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_4445 0.0098 ms 71.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
  triton_mm_4451 0.0108 ms 64.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  addmm 0.0132 ms 52.9% 
  bias_addmm 0.0135 ms 51.7% 
SingleProcess AUTOTUNE benchmarking takes 0.1404 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_4465", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.6158080101013184, "best_triton_pos": 0}
AUTOTUNE addmm(4096x20005, 4096x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_4465 0.6158 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4466 0.6483 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_4462 0.6531 ms 94.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4468 0.6691 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4463 0.6921 ms 89.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_4469 0.7171 ms 85.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4460 0.7544 ms 81.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_4464 0.8347 ms 73.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4461 0.8519 ms 72.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  bias_addmm 1.0262 ms 60.0% 
SingleProcess AUTOTUNE benchmarking takes 0.6604 seconds and 0.0002 seconds precompiling for 17 choices
eager: 0.4929s, compiled: 0.2657s
HINT_SIZE (2, 1024) RUNTIME_SIZE (32, 2048) 1.855x
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  17%|█▋        | 5/30 [00:00<00:00, 47.10it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 74.75it/s]running benchmark:  83%|████████▎ | 25/30 [00:00<00:00, 83.46it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 80.64it/s]
eager: 0.0071s, compiled: 0.0031s
HINT_SIZE (2, 2048) RUNTIME_SIZE (2, 256) 2.299x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 53.58it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 53.39it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 53.20it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 53.18it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 53.05it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 53.14it/s]
eager: 0.0114s, compiled: 0.0070s
HINT_SIZE (2, 2048) RUNTIME_SIZE (2, 1024) 1.628x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 19.85it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 19.79it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 19.82it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 19.84it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 19.85it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 19.85it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 19.84it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 19.85it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 19.83it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 19.82it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 19.83it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 19.84it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 19.84it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 19.84it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.84it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.83it/s]
eager: 0.0329s, compiled: 0.0168s
HINT_SIZE (2, 2048) RUNTIME_SIZE (2, 2048) 1.952x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:00, 70.29it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 70.67it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 70.74it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 70.63it/s]
eager: 0.0079s, compiled: 0.0058s
HINT_SIZE (2, 2048) RUNTIME_SIZE (8, 256) 1.354x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 15.74it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 15.68it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 15.66it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 15.66it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 15.66it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 15.66it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:01, 15.66it/s]running benchmark:  53%|█████▎    | 16/30 [00:01<00:00, 15.65it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 15.64it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 15.64it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 15.63it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 15.64it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 15.64it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 15.63it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 15.63it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 15.64it/s]
eager: 0.0390s, compiled: 0.0241s
HINT_SIZE (2, 2048) RUNTIME_SIZE (8, 1024) 1.619x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:05,  5.23it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:05,  5.22it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  5.22it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:04,  5.22it/s]running benchmark:  17%|█▋        | 5/30 [00:00<00:04,  5.23it/s]running benchmark:  20%|██        | 6/30 [00:01<00:04,  5.23it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  5.22it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  5.22it/s]running benchmark:  30%|███       | 9/30 [00:01<00:04,  5.23it/s]running benchmark:  33%|███▎      | 10/30 [00:01<00:03,  5.23it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:03,  5.23it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  5.23it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  5.23it/s]running benchmark:  47%|████▋     | 14/30 [00:02<00:03,  5.23it/s]running benchmark:  50%|█████     | 15/30 [00:02<00:02,  5.23it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:02,  5.23it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  5.23it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  5.23it/s]running benchmark:  63%|██████▎   | 19/30 [00:03<00:02,  5.23it/s]running benchmark:  67%|██████▋   | 20/30 [00:03<00:01,  5.23it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:01,  5.23it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  5.23it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  5.23it/s]running benchmark:  80%|████████  | 24/30 [00:04<00:01,  5.23it/s]running benchmark:  83%|████████▎ | 25/30 [00:04<00:00,  5.23it/s]running benchmark:  87%|████████▋ | 26/30 [00:04<00:00,  5.23it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  5.23it/s]running benchmark:  93%|█████████▎| 28/30 [00:05<00:00,  5.23it/s]running benchmark:  97%|█████████▋| 29/30 [00:05<00:00,  5.23it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.23it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.23it/s]
eager: 0.1250s, compiled: 0.0649s
HINT_SIZE (2, 2048) RUNTIME_SIZE (8, 2048) 1.927x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:01, 23.84it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 23.90it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 23.93it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 23.93it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 23.94it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 23.95it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 23.96it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 23.97it/s]running benchmark:  90%|█████████ | 27/30 [00:01<00:00, 23.96it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 23.83it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 23.90it/s]
eager: 0.0209s, compiled: 0.0202s
HINT_SIZE (2, 2048) RUNTIME_SIZE (32, 256) 1.034x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:07,  4.03it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.02it/s]running benchmark:  10%|█         | 3/30 [00:00<00:06,  4.02it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:06,  4.02it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:06,  4.02it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.02it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:05,  4.02it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:05,  4.02it/s]running benchmark:  30%|███       | 9/30 [00:02<00:05,  4.02it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.02it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.02it/s]running benchmark:  40%|████      | 12/30 [00:02<00:04,  4.02it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:04,  4.02it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.02it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.02it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.02it/s]running benchmark:  57%|█████▋    | 17/30 [00:04<00:03,  4.02it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:02,  4.02it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.02it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.02it/s]running benchmark:  70%|███████   | 21/30 [00:05<00:02,  4.02it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:01,  4.02it/s]running benchmark:  77%|███████▋  | 23/30 [00:05<00:01,  4.02it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.02it/s]running benchmark:  83%|████████▎ | 25/30 [00:06<00:01,  4.02it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:00,  4.02it/s]running benchmark:  90%|█████████ | 27/30 [00:06<00:00,  4.02it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.02it/s]running benchmark:  97%|█████████▋| 29/30 [00:07<00:00,  4.02it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.02it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.02it/s]
eager: 0.1527s, compiled: 0.0946s
HINT_SIZE (2, 2048) RUNTIME_SIZE (32, 1024) 1.615x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:21,  1.33it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:21,  1.33it/s]running benchmark:  10%|█         | 3/30 [00:02<00:20,  1.33it/s]running benchmark:  13%|█▎        | 4/30 [00:03<00:19,  1.33it/s]running benchmark:  17%|█▋        | 5/30 [00:03<00:18,  1.33it/s]running benchmark:  20%|██        | 6/30 [00:04<00:18,  1.33it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:17,  1.33it/s]running benchmark:  27%|██▋       | 8/30 [00:06<00:16,  1.33it/s]running benchmark:  30%|███       | 9/30 [00:06<00:15,  1.33it/s]running benchmark:  33%|███▎      | 10/30 [00:07<00:15,  1.33it/s]running benchmark:  37%|███▋      | 11/30 [00:08<00:14,  1.33it/s]running benchmark:  40%|████      | 12/30 [00:09<00:13,  1.33it/s]running benchmark:  43%|████▎     | 13/30 [00:09<00:12,  1.33it/s]running benchmark:  47%|████▋     | 14/30 [00:10<00:12,  1.33it/s]running benchmark:  50%|█████     | 15/30 [00:11<00:11,  1.33it/s]running benchmark:  53%|█████▎    | 16/30 [00:12<00:10,  1.33it/s]running benchmark:  57%|█████▋    | 17/30 [00:12<00:09,  1.33it/s]running benchmark:  60%|██████    | 18/30 [00:13<00:09,  1.33it/s]running benchmark:  63%|██████▎   | 19/30 [00:14<00:08,  1.33it/s]running benchmark:  67%|██████▋   | 20/30 [00:15<00:07,  1.33it/s]running benchmark:  70%|███████   | 21/30 [00:15<00:06,  1.33it/s]running benchmark:  73%|███████▎  | 22/30 [00:16<00:06,  1.33it/s]running benchmark:  77%|███████▋  | 23/30 [00:17<00:05,  1.33it/s]running benchmark:  80%|████████  | 24/30 [00:18<00:04,  1.33it/s]running benchmark:  83%|████████▎ | 25/30 [00:18<00:03,  1.33it/s]running benchmark:  87%|████████▋ | 26/30 [00:19<00:03,  1.33it/s]running benchmark:  90%|█████████ | 27/30 [00:20<00:02,  1.33it/s]running benchmark:  93%|█████████▎| 28/30 [00:21<00:01,  1.33it/s]running benchmark:  97%|█████████▋| 29/30 [00:21<00:00,  1.33it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.33it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.33it/s]
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.03580800071358681, "best_triton_pos": 1, "best_triton_time": 0.042367998510599136, "best_triton_kernel": "triton_mm_4569", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(2048x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.0358 ms 100.0% 
  triton_mm_4569 0.0424 ms 84.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4572 0.0443 ms 80.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4575 0.0454 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4573 0.0460 ms 77.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_4576 0.0460 ms 77.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4570 0.0466 ms 76.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_4571 0.0551 ms 65.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4567 0.0552 ms 64.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_4574 0.0580 ms 61.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.2875 seconds and 0.0005 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.04835199937224388, "best_triton_pos": 1, "best_triton_time": 0.050464000552892685, "best_triton_kernel": "triton_mm_5927", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8"}
AUTOTUNE mm(2048x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  mm 0.0484 ms 100.0% 
  triton_mm_5927 0.0505 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_5933 0.0511 ms 94.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5930 0.0514 ms 94.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_5929 0.0600 ms 80.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5926 0.0604 ms 80.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5932 0.0624 ms 77.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5928 0.0661 ms 73.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5925 0.0716 ms 67.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_mm_5924 0.0857 ms 56.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.2908 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_4555", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.01692800037562847, "best_triton_pos": 0}
AUTOTUNE mm(2048x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  triton_mm_4555 0.0169 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_4558 0.0173 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  mm 0.0177 ms 95.8% 
  triton_mm_4561 0.0179 ms 94.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4554 0.0185 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4557 0.0190 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4560 0.0196 ms 86.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4556 0.0221 ms 76.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_4553 0.0238 ms 71.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_mm_4552 0.0252 ms 67.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.2050 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "bmm", "best_time": 0.020800000056624413, "best_triton_pos": 1, "best_triton_time": 0.021023999899625778, "best_triton_kernel": "triton_bmm_4511", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE bmm(96x256x64, 96x64x256)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  bmm 0.0208 ms 100.0% 
  triton_bmm_4511 0.0210 ms 98.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_4512 0.0212 ms 98.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  triton_bmm_4515 0.0240 ms 86.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_4505 0.0258 ms 80.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_4513 0.0258 ms 80.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_4517 0.0260 ms 80.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_4514 0.0272 ms 76.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_4509 0.0280 ms 74.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_4506 0.0281 ms 74.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.2296 seconds and 0.0002 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 0.028095999732613564, "best_triton_pos": 1, "best_triton_time": 0.0289280004799366, "best_triton_kernel": "triton_bmm_4535", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(96x256x256, 96x256x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 0.0281 ms 100.0% 
  triton_bmm_4535 0.0289 ms 97.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_4538 0.0317 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_4545 0.0318 ms 88.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_4540 0.0332 ms 84.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_4543 0.0337 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_4544 0.0339 ms 82.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_4541 0.0349 ms 80.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_4534 0.0351 ms 80.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_4539 0.0371 ms 75.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.1844 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_5944", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1", "best_time": 0.007104000076651573, "best_triton_pos": 0}
AUTOTUNE addmm(8x2, 8x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_5944 0.0071 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_5937 0.0072 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_5943 0.0072 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_5936 0.0079 ms 89.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_5940 0.0083 ms 85.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  triton_mm_5942 0.0088 ms 80.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_5935 0.0098 ms 72.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
  triton_mm_5941 0.0113 ms 63.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  addmm 0.0130 ms 54.5% 
  bias_addmm 0.0139 ms 51.0% 
SingleProcess AUTOTUNE benchmarking takes 0.1348 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_5955", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.3078399896621704, "best_triton_pos": 0}
AUTOTUNE addmm(2048x20005, 2048x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_5955 0.3078 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5956 0.3220 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_5952 0.3302 ms 93.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5958 0.3430 ms 89.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5953 0.3475 ms 88.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_5959 0.3669 ms 83.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5950 0.3818 ms 80.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_5954 0.4215 ms 73.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_5951 0.4319 ms 71.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  bias_addmm 0.5147 ms 59.8% 
SingleProcess AUTOTUNE benchmarking takes 0.6102 seconds and 0.0002 seconds precompiling for 17 choices
eager: 0.4931s, compiled: 0.2563s
HINT_SIZE (2, 2048) RUNTIME_SIZE (32, 2048) 1.924x
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:00, 95.42it/s]running benchmark:  67%|██████▋   | 20/30 [00:00<00:00, 96.27it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 97.35it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 96.90it/s]
eager: 0.0072s, compiled: 0.0026s
HINT_SIZE (8, 256) RUNTIME_SIZE (2, 256) 2.757x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 50.93it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 50.91it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 50.82it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 50.86it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 50.88it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 50.86it/s]
eager: 0.0114s, compiled: 0.0078s
HINT_SIZE (8, 256) RUNTIME_SIZE (2, 1024) 1.457x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 17.29it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 17.31it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 17.32it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 17.33it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 17.33it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 17.34it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 17.33it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 17.34it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 17.33it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 17.34it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 17.34it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 17.34it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 17.34it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 17.34it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 17.34it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 17.33it/s]
eager: 0.0329s, compiled: 0.0240s
HINT_SIZE (8, 256) RUNTIME_SIZE (2, 2048) 1.370x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 81.42it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 81.93it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 82.21it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 82.08it/s]
eager: 0.0077s, compiled: 0.0040s
HINT_SIZE (8, 256) RUNTIME_SIZE (8, 256) 1.926x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 14.81it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 14.78it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 14.77it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 14.76it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 14.76it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 14.76it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:01, 14.76it/s]running benchmark:  53%|█████▎    | 16/30 [00:01<00:00, 14.76it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 14.74it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 14.74it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 14.75it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 14.75it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 14.75it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 14.76it/s]running benchmark: 100%|██████████| 30/30 [00:02<00:00, 14.76it/s]running benchmark: 100%|██████████| 30/30 [00:02<00:00, 14.76it/s]
eager: 0.0391s, compiled: 0.0280s
HINT_SIZE (8, 256) RUNTIME_SIZE (8, 1024) 1.397x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:06,  4.62it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.61it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  4.61it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:05,  4.61it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:05,  4.61it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.61it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  4.61it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  4.61it/s]running benchmark:  30%|███       | 9/30 [00:01<00:04,  4.61it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.61it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.61it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  4.61it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  4.61it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.61it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.61it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.61it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  4.61it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  4.61it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.61it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.61it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:01,  4.61it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  4.61it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  4.61it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.61it/s]running benchmark:  83%|████████▎ | 25/30 [00:05<00:01,  4.61it/s]running benchmark:  87%|████████▋ | 26/30 [00:05<00:00,  4.61it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  4.61it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.61it/s]running benchmark:  97%|█████████▋| 29/30 [00:06<00:00,  4.61it/s]running benchmark: 100%|██████████| 30/30 [00:06<00:00,  4.61it/s]running benchmark: 100%|██████████| 30/30 [00:06<00:00,  4.61it/s]
eager: 0.1251s, compiled: 0.0905s
HINT_SIZE (8, 256) RUNTIME_SIZE (8, 2048) 1.382x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:00, 27.70it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 27.42it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 27.23it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 27.12it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 27.16it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 27.34it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 27.43it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 27.61it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 27.76it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.85it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.55it/s]
eager: 0.0210s, compiled: 0.0145s
HINT_SIZE (8, 256) RUNTIME_SIZE (32, 256) 1.444x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:07,  3.84it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:07,  3.83it/s]running benchmark:  10%|█         | 3/30 [00:00<00:07,  3.83it/s]running benchmark:  13%|█▎        | 4/30 [00:01<00:06,  3.83it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:06,  3.83it/s]running benchmark:  20%|██        | 6/30 [00:01<00:06,  3.82it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:06,  3.82it/s]running benchmark:  27%|██▋       | 8/30 [00:02<00:05,  3.82it/s]running benchmark:  30%|███       | 9/30 [00:02<00:05,  3.82it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:05,  3.82it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  3.82it/s]running benchmark:  40%|████      | 12/30 [00:03<00:04,  3.82it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:04,  3.82it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:04,  3.82it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  3.82it/s]running benchmark:  53%|█████▎    | 16/30 [00:04<00:03,  3.82it/s]running benchmark:  57%|█████▋    | 17/30 [00:04<00:03,  3.82it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:03,  3.82it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  3.82it/s]running benchmark:  67%|██████▋   | 20/30 [00:05<00:02,  3.82it/s]running benchmark:  70%|███████   | 21/30 [00:05<00:02,  3.82it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:02,  3.82it/s]running benchmark:  77%|███████▋  | 23/30 [00:06<00:01,  3.82it/s]running benchmark:  80%|████████  | 24/30 [00:06<00:01,  3.82it/s]running benchmark:  83%|████████▎ | 25/30 [00:06<00:01,  3.82it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:01,  3.82it/s]running benchmark:  90%|█████████ | 27/30 [00:07<00:00,  3.82it/s]running benchmark:  93%|█████████▎| 28/30 [00:07<00:00,  3.82it/s]running benchmark:  97%|█████████▋| 29/30 [00:07<00:00,  3.82it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  3.82it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  3.82it/s]
eager: 0.1527s, compiled: 0.1074s
HINT_SIZE (8, 256) RUNTIME_SIZE (32, 1024) 1.422x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:24,  1.18it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:23,  1.18it/s]running benchmark:  10%|█         | 3/30 [00:02<00:22,  1.18it/s]running benchmark:  13%|█▎        | 4/30 [00:03<00:22,  1.18it/s]running benchmark:  17%|█▋        | 5/30 [00:04<00:21,  1.18it/s]running benchmark:  20%|██        | 6/30 [00:05<00:20,  1.18it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:19,  1.18it/s]running benchmark:  27%|██▋       | 8/30 [00:06<00:18,  1.18it/s]running benchmark:  30%|███       | 9/30 [00:07<00:17,  1.18it/s]running benchmark:  33%|███▎      | 10/30 [00:08<00:16,  1.18it/s]running benchmark:  37%|███▋      | 11/30 [00:09<00:16,  1.18it/s]running benchmark:  40%|████      | 12/30 [00:10<00:15,  1.18it/s]running benchmark:  43%|████▎     | 13/30 [00:11<00:14,  1.18it/s]running benchmark:  47%|████▋     | 14/30 [00:11<00:13,  1.18it/s]running benchmark:  50%|█████     | 15/30 [00:12<00:12,  1.18it/s]running benchmark:  53%|█████▎    | 16/30 [00:13<00:11,  1.18it/s]running benchmark:  57%|█████▋    | 17/30 [00:14<00:11,  1.18it/s]running benchmark:  60%|██████    | 18/30 [00:15<00:10,  1.18it/s]running benchmark:  63%|██████▎   | 19/30 [00:16<00:09,  1.18it/s]running benchmark:  67%|██████▋   | 20/30 [00:16<00:08,  1.18it/s]running benchmark:  70%|███████   | 21/30 [00:17<00:07,  1.18it/s]running benchmark:  73%|███████▎  | 22/30 [00:18<00:06,  1.18it/s]running benchmark:  77%|███████▋  | 23/30 [00:19<00:05,  1.18it/s]running benchmark:  80%|████████  | 24/30 [00:20<00:05,  1.18it/s]running benchmark:  83%|████████▎ | 25/30 [00:21<00:04,  1.18it/s]running benchmark:  87%|████████▋ | 26/30 [00:22<00:03,  1.18it/s]running benchmark:  90%|█████████ | 27/30 [00:22<00:02,  1.18it/s]running benchmark:  93%|█████████▎| 28/30 [00:23<00:01,  1.18it/s]running benchmark:  97%|█████████▋| 29/30 [00:24<00:00,  1.18it/s]running benchmark: 100%|██████████| 30/30 [00:25<00:00,  1.18it/s]running benchmark: 100%|██████████| 30/30 [00:25<00:00,  1.18it/s]
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.11001600325107574, "best_triton_pos": 1, "best_triton_time": 0.13977600634098053, "best_triton_kernel": "triton_mm_6065", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(8192x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.1100 ms 100.0% 
  triton_mm_6065 0.1398 ms 78.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6066 0.1659 ms 66.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6059 0.1685 ms 65.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6064 0.1727 ms 63.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_6062 0.1760 ms 62.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6060 0.1806 ms 60.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_6063 0.1819 ms 60.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_6061 0.1886 ms 58.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6057 0.2225 ms 49.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5014 seconds and 0.0003 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.12095999717712402, "best_triton_pos": 1, "best_triton_time": 0.14076800644397736, "best_triton_kernel": "triton_mm_7416", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(8192x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  mm 0.1210 ms 100.0% 
  triton_mm_7416 0.1408 ms 85.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7423 0.1454 ms 83.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7422 0.1513 ms 79.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7417 0.1594 ms 75.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_7419 0.1673 ms 72.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7420 0.1736 ms 69.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_7418 0.1814 ms 66.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7414 0.2001 ms 60.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_7421 0.2034 ms 59.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.4794 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.041728001087903976, "best_triton_pos": 1, "best_triton_time": 0.04540799930691719, "best_triton_kernel": "triton_mm_6044", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(8192x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.0417 ms 100.0% 
  triton_mm_6044 0.0454 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6047 0.0476 ms 87.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6045 0.0486 ms 85.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_6050 0.0495 ms 84.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6048 0.0500 ms 83.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_6051 0.0501 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6042 0.0573 ms 72.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_6046 0.0595 ms 70.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_6049 0.0620 ms 67.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.2754 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_bmm_6001", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.2197439968585968, "best_triton_pos": 0}
AUTOTUNE bmm(96x1024x64, 96x64x1024)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  triton_bmm_6001 0.2197 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_6002 0.2206 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  bmm 0.2255 ms 97.4% 
  triton_bmm_6007 0.2479 ms 88.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_6005 0.2592 ms 84.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_5996 0.2661 ms 82.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_6003 0.2688 ms 81.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_6006 0.2732 ms 80.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_5995 0.2897 ms 75.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_6004 0.2905 ms 75.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.6830 seconds and 0.0003 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 0.24198399484157562, "best_triton_pos": 1, "best_triton_time": 0.2516480088233948, "best_triton_kernel": "triton_bmm_6025", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(96x1024x1024, 96x1024x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 0.2420 ms 100.0% 
  triton_bmm_6025 0.2516 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_6035 0.2546 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_6033 0.2603 ms 93.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_6034 0.2715 ms 89.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_6024 0.2854 ms 84.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_6036 0.2894 ms 83.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_6028 0.3168 ms 76.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_6030 0.3260 ms 74.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_6032 0.3351 ms 72.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5363 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_7427", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1", "best_time": 0.007135999854654074, "best_triton_pos": 0}
AUTOTUNE addmm(8x2, 8x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_7427 0.0071 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_7434 0.0072 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_7433 0.0072 ms 98.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_7426 0.0081 ms 87.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_7430 0.0083 ms 86.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  triton_mm_7432 0.0088 ms 80.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_7425 0.0097 ms 73.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
  triton_mm_7431 0.0110 ms 64.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  addmm 0.0129 ms 55.3% 
  bias_addmm 0.0139 ms 51.5% 
SingleProcess AUTOTUNE benchmarking takes 0.1396 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_7445", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 1.2366080284118652, "best_triton_pos": 0}
AUTOTUNE addmm(8192x20005, 8192x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_7445 1.2366 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7442 1.2766 ms 96.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7446 1.3161 ms 94.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_7448 1.3286 ms 93.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7443 1.3724 ms 90.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_7449 1.3924 ms 88.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7440 1.5000 ms 82.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_7444 1.6871 ms 73.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7441 1.7558 ms 70.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  bias_addmm 2.0143 ms 61.4% 
SingleProcess AUTOTUNE benchmarking takes 0.7565 seconds and 0.0002 seconds precompiling for 17 choices
eager: 0.4930s, compiled: 0.3536s
HINT_SIZE (8, 256) RUNTIME_SIZE (32, 2048) 1.394x
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:00, 36.30it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 70.03it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 81.40it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 77.87it/s]
eager: 0.0072s, compiled: 0.0030s
HINT_SIZE (8, 1024) RUNTIME_SIZE (2, 256) 2.421x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 55.58it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 55.42it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 55.37it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 55.35it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 55.36it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 55.36it/s]
eager: 0.0114s, compiled: 0.0063s
HINT_SIZE (8, 1024) RUNTIME_SIZE (2, 1024) 1.815x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 19.94it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 19.89it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 19.88it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 19.89it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 19.89it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 19.89it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 19.89it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 19.86it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 19.87it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 19.86it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 19.83it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 19.82it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 19.83it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 19.85it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.78it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.84it/s]
eager: 0.0328s, compiled: 0.0168s
HINT_SIZE (8, 1024) RUNTIME_SIZE (2, 2048) 1.955x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:00, 74.35it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 76.53it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 77.42it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 77.26it/s]
eager: 0.0079s, compiled: 0.0045s
HINT_SIZE (8, 1024) RUNTIME_SIZE (8, 256) 1.762x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 16.46it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 16.42it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 16.40it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 16.38it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 16.38it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 16.40it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 16.40it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 16.41it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 16.37it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 16.38it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 16.39it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 16.38it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 16.38it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 16.39it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.36it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.38it/s]
eager: 0.0390s, compiled: 0.0212s
HINT_SIZE (8, 1024) RUNTIME_SIZE (8, 1024) 1.836x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:05,  5.31it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:05,  5.30it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  5.30it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:04,  5.30it/s]running benchmark:  17%|█▋        | 5/30 [00:00<00:04,  5.30it/s]running benchmark:  20%|██        | 6/30 [00:01<00:04,  5.30it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  5.30it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  5.30it/s]running benchmark:  30%|███       | 9/30 [00:01<00:03,  5.30it/s]running benchmark:  33%|███▎      | 10/30 [00:01<00:03,  5.30it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:03,  5.31it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  5.31it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  5.30it/s]running benchmark:  47%|████▋     | 14/30 [00:02<00:03,  5.30it/s]running benchmark:  50%|█████     | 15/30 [00:02<00:02,  5.30it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:02,  5.30it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  5.31it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  5.31it/s]running benchmark:  63%|██████▎   | 19/30 [00:03<00:02,  5.31it/s]running benchmark:  67%|██████▋   | 20/30 [00:03<00:01,  5.30it/s]running benchmark:  70%|███████   | 21/30 [00:03<00:01,  5.31it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  5.31it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  5.31it/s]running benchmark:  80%|████████  | 24/30 [00:04<00:01,  5.31it/s]running benchmark:  83%|████████▎ | 25/30 [00:04<00:00,  5.31it/s]running benchmark:  87%|████████▋ | 26/30 [00:04<00:00,  5.31it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  5.31it/s]running benchmark:  93%|█████████▎| 28/30 [00:05<00:00,  5.31it/s]running benchmark:  97%|█████████▋| 29/30 [00:05<00:00,  5.31it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.31it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.30it/s]
eager: 0.1250s, compiled: 0.0622s
HINT_SIZE (8, 1024) RUNTIME_SIZE (8, 2048) 2.010x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:01, 26.99it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 27.24it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 27.30it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 27.36it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 27.38it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 27.40it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 27.41it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 27.25it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 27.25it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.30it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.30it/s]
eager: 0.0209s, compiled: 0.0151s
HINT_SIZE (8, 1024) RUNTIME_SIZE (32, 256) 1.385x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:06,  4.27it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.26it/s]running benchmark:  10%|█         | 3/30 [00:00<00:06,  4.26it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:06,  4.26it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:05,  4.26it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.26it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:05,  4.26it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:05,  4.26it/s]running benchmark:  30%|███       | 9/30 [00:02<00:04,  4.26it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.26it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.26it/s]running benchmark:  40%|████      | 12/30 [00:02<00:04,  4.26it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:03,  4.25it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.25it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.25it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.25it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:03,  4.25it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:02,  4.25it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.25it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.25it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:02,  4.25it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:01,  4.26it/s]running benchmark:  77%|███████▋  | 23/30 [00:05<00:01,  4.26it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.25it/s]running benchmark:  83%|████████▎ | 25/30 [00:05<00:01,  4.25it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:00,  4.26it/s]running benchmark:  90%|█████████ | 27/30 [00:06<00:00,  4.26it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.26it/s]running benchmark:  97%|█████████▋| 29/30 [00:06<00:00,  4.26it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.26it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.26it/s]
eager: 0.1527s, compiled: 0.0809s
HINT_SIZE (8, 1024) RUNTIME_SIZE (32, 1024) 1.889x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:21,  1.36it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:20,  1.36it/s]running benchmark:  10%|█         | 3/30 [00:02<00:19,  1.36it/s]running benchmark:  13%|█▎        | 4/30 [00:02<00:19,  1.36it/s]running benchmark:  17%|█▋        | 5/30 [00:03<00:18,  1.36it/s]running benchmark:  20%|██        | 6/30 [00:04<00:17,  1.36it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:16,  1.36it/s]running benchmark:  27%|██▋       | 8/30 [00:05<00:16,  1.36it/s]running benchmark:  30%|███       | 9/30 [00:06<00:15,  1.36it/s]running benchmark:  33%|███▎      | 10/30 [00:07<00:14,  1.36it/s]running benchmark:  37%|███▋      | 11/30 [00:08<00:13,  1.36it/s]running benchmark:  40%|████      | 12/30 [00:08<00:13,  1.36it/s]running benchmark:  43%|████▎     | 13/30 [00:09<00:12,  1.36it/s]running benchmark:  47%|████▋     | 14/30 [00:10<00:11,  1.36it/s]running benchmark:  50%|█████     | 15/30 [00:11<00:11,  1.36it/s]running benchmark:  53%|█████▎    | 16/30 [00:11<00:10,  1.36it/s]running benchmark:  57%|█████▋    | 17/30 [00:12<00:09,  1.36it/s]running benchmark:  60%|██████    | 18/30 [00:13<00:08,  1.36it/s]running benchmark:  63%|██████▎   | 19/30 [00:13<00:08,  1.36it/s]running benchmark:  67%|██████▋   | 20/30 [00:14<00:07,  1.36it/s]running benchmark:  70%|███████   | 21/30 [00:15<00:06,  1.36it/s]running benchmark:  73%|███████▎  | 22/30 [00:16<00:05,  1.36it/s]running benchmark:  77%|███████▋  | 23/30 [00:16<00:05,  1.36it/s]running benchmark:  80%|████████  | 24/30 [00:17<00:04,  1.36it/s]running benchmark:  83%|████████▎ | 25/30 [00:18<00:03,  1.36it/s]running benchmark:  87%|████████▋ | 26/30 [00:19<00:02,  1.36it/s]running benchmark:  90%|█████████ | 27/30 [00:19<00:02,  1.36it/s]running benchmark:  93%|█████████▎| 28/30 [00:20<00:01,  1.36it/s]running benchmark:  97%|█████████▋| 29/30 [00:21<00:00,  1.36it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.36it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.36it/s]
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.2186879962682724, "best_triton_pos": 1, "best_triton_time": 0.2743679881095886, "best_triton_kernel": "triton_mm_7555", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(16384x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.2187 ms 100.0% 
  triton_mm_7555 0.2744 ms 79.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7549 0.3420 ms 64.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7556 0.3433 ms 63.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7554 0.3438 ms 63.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_7550 0.3514 ms 62.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_7552 0.3608 ms 60.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7553 0.3614 ms 60.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_7551 0.3822 ms 57.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7547 0.4421 ms 49.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5813 seconds and 0.0003 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.22553600370883942, "best_triton_pos": 1, "best_triton_time": 0.24163199961185455, "best_triton_kernel": "triton_mm_8912", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(16384x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  mm 0.2255 ms 100.0% 
  triton_mm_8912 0.2416 ms 93.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8906 0.2919 ms 77.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8913 0.2968 ms 76.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8911 0.3109 ms 72.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_8907 0.3259 ms 69.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_8910 0.3455 ms 65.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_8909 0.3485 ms 64.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8908 0.3582 ms 63.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8904 0.4138 ms 54.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5705 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.0716480016708374, "best_triton_pos": 1, "best_triton_time": 0.07692799717187881, "best_triton_kernel": "triton_mm_7540", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(16384x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.0716 ms 100.0% 
  triton_mm_7540 0.0769 ms 93.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7534 0.0858 ms 83.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7541 0.0904 ms 79.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7537 0.0905 ms 79.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7535 0.0929 ms 77.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_7539 0.0955 ms 75.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_7538 0.0959 ms 74.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_7536 0.1078 ms 66.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_7532 0.1094 ms 65.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.3701 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_bmm_7491", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.7885119915008545, "best_triton_pos": 0}
AUTOTUNE bmm(96x2048x64, 96x64x2048)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  triton_bmm_7491 0.7885 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_7492 0.7889 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  bmm 0.8390 ms 94.0% 
  triton_bmm_7493 0.9098 ms 86.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_7486 0.9278 ms 85.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_7495 0.9541 ms 82.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_7497 0.9565 ms 82.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_7496 0.9988 ms 78.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_7494 1.0174 ms 77.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_7485 1.0228 ms 77.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.7424 seconds and 0.0002 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 0.8576639890670776, "best_triton_pos": 1, "best_triton_time": 0.9168639779090881, "best_triton_kernel": "triton_bmm_7515", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(96x2048x2048, 96x2048x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 0.8577 ms 100.0% 
  triton_bmm_7515 0.9169 ms 93.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_7525 0.9498 ms 90.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_7523 0.9548 ms 89.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_7524 0.9639 ms 89.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_7526 0.9873 ms 86.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_7514 1.0408 ms 82.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_7518 1.1724 ms 73.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_7520 1.2190 ms 70.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_7522 1.2218 ms 70.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5914 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_8924", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1", "best_time": 0.007071999832987785, "best_triton_pos": 0}
AUTOTUNE addmm(8x2, 8x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_8924 0.0071 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_8917 0.0071 ms 99.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_8923 0.0073 ms 97.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_8916 0.0080 ms 88.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
  triton_mm_8920 0.0084 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  triton_mm_8922 0.0090 ms 78.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
  triton_mm_8915 0.0098 ms 72.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
  triton_mm_8921 0.0111 ms 63.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
  addmm 0.0129 ms 54.8% 
  bias_addmm 0.0137 ms 51.6% 
SingleProcess AUTOTUNE benchmarking takes 0.1360 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_8935", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 2.4759678840637207, "best_triton_pos": 0}
AUTOTUNE addmm(16384x20005, 16384x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_8935 2.4760 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8932 2.5242 ms 98.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8938 2.6418 ms 93.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8936 2.6892 ms 92.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_8933 2.7892 ms 88.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_8930 2.9971 ms 82.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_8939 3.1303 ms 79.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8934 3.2569 ms 76.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_8931 3.4497 ms 71.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  bias_addmm 3.9944 ms 62.0% 
SingleProcess AUTOTUNE benchmarking takes 0.9569 seconds and 0.0002 seconds precompiling for 17 choices
eager: 0.4932s, compiled: 0.2419s
HINT_SIZE (8, 1024) RUNTIME_SIZE (32, 2048) 2.039x
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:06,  4.45it/s]running benchmark:  37%|███▋      | 11/30 [00:00<00:00, 41.32it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 61.80it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 57.61it/s]
eager: 0.0069s, compiled: 0.0029s
HINT_SIZE (8, 2048) RUNTIME_SIZE (2, 256) 2.386x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 54.52it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 54.32it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 53.88it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 53.75it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 53.68it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 53.82it/s]
eager: 0.0113s, compiled: 0.0068s
HINT_SIZE (8, 2048) RUNTIME_SIZE (2, 1024) 1.667x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 19.85it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 19.89it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 19.92it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 19.92it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 19.89it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 19.86it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 19.87it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 19.90it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 19.93it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 19.95it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 19.95it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 19.95it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 19.96it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 19.95it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.95it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.92it/s]
eager: 0.0327s, compiled: 0.0169s
HINT_SIZE (8, 2048) RUNTIME_SIZE (2, 2048) 1.937x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:00, 72.66it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 72.35it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 72.62it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 72.71it/s]
eager: 0.0077s, compiled: 0.0056s
HINT_SIZE (8, 2048) RUNTIME_SIZE (8, 256) 1.374x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 15.98it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 15.93it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 15.86it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 15.85it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 15.87it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 15.88it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:01, 15.89it/s]running benchmark:  53%|█████▎    | 16/30 [00:01<00:00, 15.90it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 15.90it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 15.88it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 15.89it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 15.91it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 15.91it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 15.93it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 15.93it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 15.90it/s]
eager: 0.0388s, compiled: 0.0234s
HINT_SIZE (8, 2048) RUNTIME_SIZE (8, 1024) 1.662x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:05,  5.30it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:05,  5.29it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  5.29it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:04,  5.29it/s]running benchmark:  17%|█▋        | 5/30 [00:00<00:04,  5.29it/s]running benchmark:  20%|██        | 6/30 [00:01<00:04,  5.29it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  5.29it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  5.29it/s]running benchmark:  30%|███       | 9/30 [00:01<00:03,  5.29it/s]running benchmark:  33%|███▎      | 10/30 [00:01<00:03,  5.29it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:03,  5.29it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  5.29it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  5.29it/s]running benchmark:  47%|████▋     | 14/30 [00:02<00:03,  5.29it/s]running benchmark:  50%|█████     | 15/30 [00:02<00:02,  5.29it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:02,  5.29it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  5.29it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  5.29it/s]running benchmark:  63%|██████▎   | 19/30 [00:03<00:02,  5.29it/s]running benchmark:  67%|██████▋   | 20/30 [00:03<00:01,  5.29it/s]running benchmark:  70%|███████   | 21/30 [00:03<00:01,  5.29it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  5.29it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  5.29it/s]running benchmark:  80%|████████  | 24/30 [00:04<00:01,  5.29it/s]running benchmark:  83%|████████▎ | 25/30 [00:04<00:00,  5.29it/s]running benchmark:  87%|████████▋ | 26/30 [00:04<00:00,  5.29it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  5.29it/s]running benchmark:  93%|█████████▎| 28/30 [00:05<00:00,  5.29it/s]running benchmark:  97%|█████████▋| 29/30 [00:05<00:00,  5.30it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.29it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.29it/s]
eager: 0.1248s, compiled: 0.0631s
HINT_SIZE (8, 2048) RUNTIME_SIZE (8, 2048) 1.978x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:01, 24.41it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 24.48it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 24.47it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 24.48it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 24.50it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 24.50it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 24.51it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 24.51it/s]running benchmark:  90%|█████████ | 27/30 [00:02<00:00,  5.76it/s]running benchmark: 100%|██████████| 30/30 [00:02<00:00,  7.55it/s]running benchmark: 100%|██████████| 30/30 [00:02<00:00, 12.01it/s]
eager: 0.0208s, compiled: 0.0195s
HINT_SIZE (8, 2048) RUNTIME_SIZE (32, 256) 1.065x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:07,  4.11it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.11it/s]running benchmark:  10%|█         | 3/30 [00:00<00:06,  4.10it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:06,  4.10it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:06,  4.10it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.10it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:05,  4.10it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:05,  4.10it/s]running benchmark:  30%|███       | 9/30 [00:02<00:05,  4.10it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.10it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.10it/s]running benchmark:  40%|████      | 12/30 [00:02<00:04,  4.10it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:04,  4.10it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.10it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.10it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.10it/s]running benchmark:  57%|█████▋    | 17/30 [00:04<00:03,  4.10it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:02,  4.10it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.10it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.10it/s]running benchmark:  70%|███████   | 21/30 [00:05<00:02,  4.10it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:01,  4.10it/s]running benchmark:  77%|███████▋  | 23/30 [00:05<00:01,  4.10it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.10it/s]running benchmark:  83%|████████▎ | 25/30 [00:06<00:01,  4.10it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:00,  4.10it/s]running benchmark:  90%|█████████ | 27/30 [00:06<00:00,  4.10it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.10it/s]running benchmark:  97%|█████████▋| 29/30 [00:07<00:00,  4.10it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.10it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.10it/s]
eager: 0.1526s, compiled: 0.0903s
HINT_SIZE (8, 2048) RUNTIME_SIZE (32, 1024) 1.690x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:21,  1.35it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:20,  1.35it/s]running benchmark:  10%|█         | 3/30 [00:02<00:19,  1.35it/s]running benchmark:  13%|█▎        | 4/30 [00:02<00:19,  1.35it/s]running benchmark:  17%|█▋        | 5/30 [00:03<00:18,  1.35it/s]running benchmark:  20%|██        | 6/30 [00:04<00:17,  1.35it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:17,  1.35it/s]running benchmark:  27%|██▋       | 8/30 [00:05<00:16,  1.35it/s]running benchmark:  30%|███       | 9/30 [00:06<00:15,  1.35it/s]running benchmark:  33%|███▎      | 10/30 [00:07<00:14,  1.35it/s]running benchmark:  37%|███▋      | 11/30 [00:08<00:14,  1.35it/s]running benchmark:  40%|████      | 12/30 [00:08<00:13,  1.35it/s]running benchmark:  43%|████▎     | 13/30 [00:09<00:12,  1.35it/s]running benchmark:  47%|████▋     | 14/30 [00:10<00:11,  1.35it/s]running benchmark:  50%|█████     | 15/30 [00:11<00:11,  1.35it/s]running benchmark:  53%|█████▎    | 16/30 [00:11<00:10,  1.35it/s]running benchmark:  57%|█████▋    | 17/30 [00:12<00:09,  1.35it/s]running benchmark:  60%|██████    | 18/30 [00:13<00:08,  1.35it/s]running benchmark:  63%|██████▎   | 19/30 [00:14<00:08,  1.35it/s]running benchmark:  67%|██████▋   | 20/30 [00:14<00:07,  1.35it/s]running benchmark:  70%|███████   | 21/30 [00:15<00:06,  1.35it/s]running benchmark:  73%|███████▎  | 22/30 [00:16<00:05,  1.35it/s]running benchmark:  77%|███████▋  | 23/30 [00:17<00:05,  1.35it/s]running benchmark:  80%|████████  | 24/30 [00:17<00:04,  1.35it/s]running benchmark:  83%|████████▎ | 25/30 [00:18<00:03,  1.35it/s]running benchmark:  87%|████████▋ | 26/30 [00:19<00:02,  1.35it/s]running benchmark:  90%|█████████ | 27/30 [00:20<00:02,  1.35it/s]running benchmark:  93%|█████████▎| 28/30 [00:20<00:01,  1.35it/s]running benchmark:  97%|█████████▋| 29/30 [00:21<00:00,  1.35it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.35it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.35it/s]
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.11059200018644333, "best_triton_pos": 1, "best_triton_time": 0.1380160003900528, "best_triton_kernel": "triton_mm_9045", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(8192x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.1106 ms 100.0% 
  triton_mm_9045 0.1380 ms 80.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9046 0.1678 ms 65.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9039 0.1707 ms 64.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9044 0.1743 ms 63.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_9042 0.1753 ms 63.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9040 0.1785 ms 62.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_9043 0.1830 ms 60.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_9041 0.1921 ms 57.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9037 0.2151 ms 51.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.4894 seconds and 0.0004 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.12121599912643433, "best_triton_pos": 1, "best_triton_time": 0.14022399485111237, "best_triton_kernel": "triton_mm_10396", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(8192x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  mm 0.1212 ms 100.0% 
  triton_mm_10396 0.1402 ms 86.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10403 0.1452 ms 83.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10402 0.1509 ms 80.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10397 0.1577 ms 76.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_10399 0.1692 ms 71.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10400 0.1702 ms 71.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_10398 0.1820 ms 66.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10394 0.1982 ms 61.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_10401 0.2025 ms 59.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.4799 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.041439998894929886, "best_triton_pos": 1, "best_triton_time": 0.04508800059556961, "best_triton_kernel": "triton_mm_9024", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(8192x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.0414 ms 100.0% 
  triton_mm_9024 0.0451 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9027 0.0474 ms 87.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9030 0.0484 ms 85.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9025 0.0485 ms 85.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_9031 0.0489 ms 84.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9028 0.0497 ms 83.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_9022 0.0574 ms 72.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_9026 0.0602 ms 68.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_9029 0.0615 ms 67.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.2734 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_bmm_8981", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.07414399832487106, "best_triton_pos": 0}
AUTOTUNE bmm(384x256x64, 384x64x256)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  triton_bmm_8981 0.0741 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_8982 0.0742 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  bmm 0.0770 ms 96.3% 
  triton_bmm_8987 0.0806 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_8985 0.0816 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_8975 0.0883 ms 83.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_8977 0.0892 ms 83.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  triton_bmm_8976 0.0896 ms 82.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_8978 0.0900 ms 82.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
  triton_bmm_8986 0.0910 ms 81.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.3689 seconds and 0.0002 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 0.08495999872684479, "best_triton_pos": 1, "best_triton_time": 0.08707199990749359, "best_triton_kernel": "triton_bmm_9005", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(384x256x256, 384x256x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 0.0850 ms 100.0% 
  triton_bmm_9005 0.0871 ms 97.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_9015 0.0916 ms 92.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_9013 0.0951 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_9014 0.0964 ms 88.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_9004 0.1034 ms 82.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_9008 0.1037 ms 81.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_9010 0.1072 ms 79.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_9016 0.1118 ms 76.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_9011 0.1132 ms 75.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 0.3104 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_10407", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.007424000184983015, "best_triton_pos": 0}
AUTOTUNE addmm(32x2, 32x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_10407 0.0074 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_10413 0.0075 ms 99.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
  triton_mm_10414 0.0080 ms 93.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_10406 0.0086 ms 85.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_10410 0.0092 ms 80.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
  triton_mm_10412 0.0097 ms 76.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
  triton_mm_10405 0.0106 ms 70.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
  triton_mm_10411 0.0124 ms 59.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
  addmm 0.0133 ms 55.9% 
  bias_addmm 0.0139 ms 53.5% 
SingleProcess AUTOTUNE benchmarking takes 0.1390 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_10425", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 1.2393920421600342, "best_triton_pos": 0}
AUTOTUNE addmm(8192x20005, 8192x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_10425 1.2394 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10422 1.2810 ms 96.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10428 1.3216 ms 93.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10426 1.3227 ms 93.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_10423 1.3649 ms 90.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_10429 1.4048 ms 88.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10420 1.5009 ms 82.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_10424 1.6742 ms 74.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10421 1.7251 ms 71.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  bias_addmm 2.0151 ms 61.5% 
SingleProcess AUTOTUNE benchmarking takes 0.7521 seconds and 0.0002 seconds precompiling for 17 choices
eager: 0.4930s, compiled: 0.2470s
HINT_SIZE (8, 2048) RUNTIME_SIZE (32, 2048) 1.996x
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  23%|██▎       | 7/30 [00:00<00:00, 64.71it/s]running benchmark:  57%|█████▋    | 17/30 [00:00<00:00, 84.22it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 90.82it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 87.99it/s]
eager: 0.0069s, compiled: 0.0028s
HINT_SIZE (32, 256) RUNTIME_SIZE (2, 256) 2.492x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 56.12it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 55.96it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 55.92it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 55.90it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 55.85it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 55.88it/s]
eager: 0.0113s, compiled: 0.0062s
HINT_SIZE (32, 256) RUNTIME_SIZE (2, 1024) 1.821x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 19.32it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 19.32it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 19.32it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 19.34it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 19.34it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 19.34it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 19.33it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 19.35it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 19.36it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 19.37it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 19.39it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 19.40it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 19.39it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 19.37it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.38it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.36it/s]
eager: 0.0327s, compiled: 0.0185s
HINT_SIZE (32, 256) RUNTIME_SIZE (2, 2048) 1.771x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 83.22it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 83.63it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 83.57it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 83.48it/s]
eager: 0.0076s, compiled: 0.0040s
HINT_SIZE (32, 256) RUNTIME_SIZE (8, 256) 1.921x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 16.64it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 16.60it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 16.59it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 16.56it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 16.56it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 16.56it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 16.57it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 16.57it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 16.57it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 16.57it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 16.56it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 16.56it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 16.56it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 16.58it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.58it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.57it/s]
eager: 0.0389s, compiled: 0.0208s
HINT_SIZE (32, 256) RUNTIME_SIZE (8, 1024) 1.865x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:05,  5.08it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:05,  5.07it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  5.07it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:05,  5.06it/s]running benchmark:  17%|█▋        | 5/30 [00:00<00:04,  5.07it/s]running benchmark:  20%|██        | 6/30 [00:01<00:04,  5.06it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  5.07it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  5.07it/s]running benchmark:  30%|███       | 9/30 [00:01<00:04,  5.07it/s]running benchmark:  33%|███▎      | 10/30 [00:01<00:03,  5.07it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:03,  5.07it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  5.07it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  5.07it/s]running benchmark:  47%|████▋     | 14/30 [00:02<00:03,  5.07it/s]running benchmark:  50%|█████     | 15/30 [00:02<00:02,  5.06it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:02,  5.06it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  5.07it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  5.07it/s]running benchmark:  63%|██████▎   | 19/30 [00:03<00:02,  5.07it/s]running benchmark:  67%|██████▋   | 20/30 [00:03<00:01,  5.06it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:01,  5.06it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  5.06it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  5.06it/s]running benchmark:  80%|████████  | 24/30 [00:04<00:01,  5.06it/s]running benchmark:  83%|████████▎ | 25/30 [00:04<00:00,  5.06it/s]running benchmark:  87%|████████▋ | 26/30 [00:05<00:00,  5.06it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  5.07it/s]running benchmark:  93%|█████████▎| 28/30 [00:05<00:00,  5.07it/s]running benchmark:  97%|█████████▋| 29/30 [00:05<00:00,  5.07it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.07it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.07it/s]
eager: 0.1248s, compiled: 0.0716s
HINT_SIZE (32, 256) RUNTIME_SIZE (8, 2048) 1.744x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:00, 28.90it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 28.99it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 29.02it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 29.03it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 29.04it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 29.06it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 29.06it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 29.05it/s]running benchmark:  90%|█████████ | 27/30 [00:00<00:00, 29.06it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 29.05it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 29.04it/s]
eager: 0.0208s, compiled: 0.0132s
HINT_SIZE (32, 256) RUNTIME_SIZE (32, 256) 1.576x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:06,  4.29it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.28it/s]running benchmark:  10%|█         | 3/30 [00:00<00:06,  4.28it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:06,  4.28it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:05,  4.28it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.28it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:05,  4.28it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:05,  4.28it/s]running benchmark:  30%|███       | 9/30 [00:02<00:04,  4.28it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.28it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.28it/s]running benchmark:  40%|████      | 12/30 [00:02<00:04,  4.28it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:03,  4.28it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.28it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.28it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.28it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:03,  4.28it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:02,  4.28it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.28it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.28it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:02,  4.28it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:01,  4.28it/s]running benchmark:  77%|███████▋  | 23/30 [00:05<00:01,  4.28it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.28it/s]running benchmark:  83%|████████▎ | 25/30 [00:05<00:01,  4.28it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:00,  4.28it/s]running benchmark:  90%|█████████ | 27/30 [00:06<00:00,  4.28it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.28it/s]running benchmark:  97%|█████████▋| 29/30 [00:06<00:00,  4.28it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.28it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.28it/s]
eager: 0.1525s, compiled: 0.0799s
HINT_SIZE (32, 256) RUNTIME_SIZE (32, 1024) 1.908x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:22,  1.29it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:21,  1.29it/s]running benchmark:  10%|█         | 3/30 [00:02<00:20,  1.29it/s]running benchmark:  13%|█▎        | 4/30 [00:03<00:20,  1.29it/s]running benchmark:  17%|█▋        | 5/30 [00:03<00:19,  1.29it/s]running benchmark:  20%|██        | 6/30 [00:04<00:18,  1.29it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:17,  1.29it/s]running benchmark:  27%|██▋       | 8/30 [00:06<00:17,  1.29it/s]running benchmark:  30%|███       | 9/30 [00:06<00:16,  1.29it/s]running benchmark:  33%|███▎      | 10/30 [00:07<00:15,  1.29it/s]running benchmark:  37%|███▋      | 11/30 [00:08<00:14,  1.29it/s]running benchmark:  40%|████      | 12/30 [00:09<00:13,  1.29it/s]running benchmark:  43%|████▎     | 13/30 [00:10<00:13,  1.29it/s]running benchmark:  47%|████▋     | 14/30 [00:10<00:12,  1.29it/s]running benchmark:  50%|█████     | 15/30 [00:11<00:11,  1.29it/s]running benchmark:  53%|█████▎    | 16/30 [00:12<00:10,  1.29it/s]running benchmark:  57%|█████▋    | 17/30 [00:13<00:10,  1.29it/s]running benchmark:  60%|██████    | 18/30 [00:13<00:09,  1.29it/s]running benchmark:  63%|██████▎   | 19/30 [00:14<00:08,  1.29it/s]running benchmark:  67%|██████▋   | 20/30 [00:15<00:07,  1.29it/s]running benchmark:  70%|███████   | 21/30 [00:16<00:06,  1.29it/s]running benchmark:  73%|███████▎  | 22/30 [00:17<00:06,  1.29it/s]running benchmark:  77%|███████▋  | 23/30 [00:17<00:05,  1.29it/s]running benchmark:  80%|████████  | 24/30 [00:18<00:04,  1.29it/s]running benchmark:  83%|████████▎ | 25/30 [00:19<00:03,  1.29it/s]running benchmark:  87%|████████▋ | 26/30 [00:20<00:03,  1.29it/s]running benchmark:  90%|█████████ | 27/30 [00:20<00:02,  1.29it/s]running benchmark:  93%|█████████▎| 28/30 [00:21<00:01,  1.29it/s]running benchmark:  97%|█████████▋| 29/30 [00:22<00:00,  1.29it/s]running benchmark: 100%|██████████| 30/30 [00:23<00:00,  1.29it/s]running benchmark: 100%|██████████| 30/30 [00:23<00:00,  1.29it/s]
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.4322560131549835, "best_triton_pos": 1, "best_triton_time": 0.5412480235099792, "best_triton_kernel": "triton_mm_10535", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(32768x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.4323 ms 100.0% 
  triton_mm_10535 0.5412 ms 79.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10536 0.6746 ms 64.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10529 0.6851 ms 63.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10530 0.6955 ms 62.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_10534 0.7012 ms 61.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_10532 0.7120 ms 60.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10533 0.7306 ms 59.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_10531 0.7705 ms 56.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10527 0.9028 ms 47.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.6200 seconds and 0.0004 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.43382400274276733, "best_triton_pos": 1, "best_triton_time": 0.4784319996833801, "best_triton_kernel": "triton_mm_11892", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(32768x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  mm 0.4338 ms 100.0% 
  triton_mm_11892 0.4784 ms 90.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11893 0.5894 ms 73.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11886 0.6126 ms 70.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11891 0.6262 ms 69.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_11887 0.6543 ms 66.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_11889 0.6975 ms 62.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11890 0.7030 ms 61.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_11888 0.7164 ms 60.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11884 0.8468 ms 51.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.6151 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.12943999469280243, "best_triton_pos": 1, "best_triton_time": 0.14870400726795197, "best_triton_kernel": "triton_mm_10520", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(32768x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.1294 ms 100.0% 
  triton_mm_10520 0.1487 ms 87.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10521 0.1716 ms 75.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10514 0.1717 ms 75.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10517 0.1766 ms 73.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10515 0.1835 ms 70.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_10519 0.1866 ms 69.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_10518 0.1894 ms 68.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_10516 0.2083 ms 62.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_10512 0.2145 ms 60.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.4998 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_bmm_10471", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.8799999952316284, "best_triton_pos": 0}
AUTOTUNE bmm(384x1024x64, 384x64x1024)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  triton_bmm_10471 0.8800 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_10472 0.8818 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  bmm 0.9006 ms 97.7% 
  triton_bmm_10477 1.0006 ms 87.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_10475 1.0154 ms 86.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_10466 1.0472 ms 84.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_10473 1.0602 ms 83.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_10476 1.0714 ms 82.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_10474 1.1328 ms 77.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_10465 1.1330 ms 77.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.7483 seconds and 0.0002 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 0.9094079732894897, "best_triton_pos": 1, "best_triton_time": 0.9352959990501404, "best_triton_kernel": "triton_bmm_10495", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(384x1024x1024, 384x1024x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 0.9094 ms 100.0% 
  triton_bmm_10495 0.9353 ms 97.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_10505 0.9684 ms 93.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_10503 0.9972 ms 91.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_10504 1.0112 ms 89.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_10494 1.0739 ms 84.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_10506 1.0900 ms 83.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_10498 1.1881 ms 76.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_10500 1.2203 ms 74.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_10502 1.2711 ms 71.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5724 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_11897", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.007327999919652939, "best_triton_pos": 0}
AUTOTUNE addmm(32x2, 32x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_11897 0.0073 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_11903 0.0075 ms 97.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
  triton_mm_11904 0.0080 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_11896 0.0084 ms 87.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_11900 0.0091 ms 80.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
  triton_mm_11902 0.0098 ms 75.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
  triton_mm_11895 0.0101 ms 72.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
  triton_mm_11901 0.0122 ms 59.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
  addmm 0.0132 ms 55.6% 
  bias_addmm 0.0137 ms 53.5% 
SingleProcess AUTOTUNE benchmarking takes 0.1388 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_11915", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 4.969727993011475, "best_triton_pos": 0}
AUTOTUNE addmm(32768x20005, 32768x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_11915 4.9697 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11918 5.2012 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11912 5.3308 ms 93.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11919 5.6411 ms 88.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_11916 5.7001 ms 87.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_11910 6.0262 ms 82.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_11913 6.0667 ms 81.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_11914 6.5968 ms 75.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  bias_addmm 7.9370 ms 62.6% 
  triton_mm_11917 8.0439 ms 61.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 1.4047 seconds and 0.0002 seconds precompiling for 17 choices
eager: 0.4930s, compiled: 0.2837s
HINT_SIZE (32, 256) RUNTIME_SIZE (32, 2048) 1.738x
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:08,  3.32it/s]running benchmark:  37%|███▋      | 11/30 [00:00<00:00, 33.72it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 53.28it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 49.24it/s]
eager: 0.0072s, compiled: 0.0030s
HINT_SIZE (32, 1024) RUNTIME_SIZE (2, 256) 2.414x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 55.40it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 55.15it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 54.94it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 55.01it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 54.91it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 54.96it/s]
eager: 0.0114s, compiled: 0.0063s
HINT_SIZE (32, 1024) RUNTIME_SIZE (2, 1024) 1.803x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 19.92it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 19.83it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 19.82it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 19.81it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 19.82it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 19.83it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 19.84it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 19.85it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 19.84it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 19.83it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 19.84it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 19.84it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 19.85it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 19.83it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.83it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.83it/s]
eager: 0.0328s, compiled: 0.0169s
HINT_SIZE (32, 1024) RUNTIME_SIZE (2, 2048) 1.946x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:00, 77.58it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 76.62it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 77.26it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 77.46it/s]
eager: 0.0079s, compiled: 0.0045s
HINT_SIZE (32, 1024) RUNTIME_SIZE (8, 256) 1.736x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 16.35it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 16.34it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 16.34it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 16.31it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 16.27it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 16.30it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 16.32it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 16.32it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 16.33it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 16.31it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 16.32it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 16.33it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 16.33it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 16.32it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.32it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 16.32it/s]
eager: 0.0390s, compiled: 0.0214s
HINT_SIZE (32, 1024) RUNTIME_SIZE (8, 1024) 1.825x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:05,  5.32it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:05,  5.31it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  5.31it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:04,  5.30it/s]running benchmark:  17%|█▋        | 5/30 [00:00<00:04,  5.30it/s]running benchmark:  20%|██        | 6/30 [00:01<00:04,  5.30it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  5.30it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  5.30it/s]running benchmark:  30%|███       | 9/30 [00:01<00:03,  5.30it/s]running benchmark:  33%|███▎      | 10/30 [00:01<00:03,  5.30it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:03,  5.30it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  5.30it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  5.30it/s]running benchmark:  47%|████▋     | 14/30 [00:02<00:03,  5.30it/s]running benchmark:  50%|█████     | 15/30 [00:02<00:02,  5.30it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:02,  5.30it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  5.30it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  5.30it/s]running benchmark:  63%|██████▎   | 19/30 [00:03<00:02,  5.30it/s]running benchmark:  67%|██████▋   | 20/30 [00:03<00:01,  5.30it/s]running benchmark:  70%|███████   | 21/30 [00:03<00:01,  5.30it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  5.30it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  5.30it/s]running benchmark:  80%|████████  | 24/30 [00:04<00:01,  5.30it/s]running benchmark:  83%|████████▎ | 25/30 [00:04<00:00,  5.30it/s]running benchmark:  87%|████████▋ | 26/30 [00:04<00:00,  5.30it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  5.30it/s]running benchmark:  93%|█████████▎| 28/30 [00:05<00:00,  5.30it/s]running benchmark:  97%|█████████▋| 29/30 [00:05<00:00,  5.30it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.30it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.30it/s]
eager: 0.1250s, compiled: 0.0623s
HINT_SIZE (32, 1024) RUNTIME_SIZE (8, 2048) 2.008x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:01, 26.55it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 26.85it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 26.97it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 26.94it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 26.84it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 26.89it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 27.01it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 27.04it/s]running benchmark:  90%|█████████ | 27/30 [00:01<00:00, 27.09it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 27.03it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 26.97it/s]
eager: 0.0209s, compiled: 0.0154s
HINT_SIZE (32, 1024) RUNTIME_SIZE (32, 256) 1.360x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:06,  4.27it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.26it/s]running benchmark:  10%|█         | 3/30 [00:00<00:06,  4.26it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:06,  4.25it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:05,  4.26it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.25it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:05,  4.25it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:05,  4.25it/s]running benchmark:  30%|███       | 9/30 [00:02<00:04,  4.25it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.25it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.25it/s]running benchmark:  40%|████      | 12/30 [00:02<00:04,  4.25it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:03,  4.25it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.25it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.25it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.25it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:03,  4.26it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:02,  4.25it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.25it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.25it/s]running benchmark:  70%|███████   | 21/30 [00:04<00:02,  4.25it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:01,  4.25it/s]running benchmark:  77%|███████▋  | 23/30 [00:05<00:01,  4.25it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.25it/s]running benchmark:  83%|████████▎ | 25/30 [00:05<00:01,  4.25it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:00,  4.25it/s]running benchmark:  90%|█████████ | 27/30 [00:06<00:00,  4.25it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.25it/s]running benchmark:  97%|█████████▋| 29/30 [00:06<00:00,  4.25it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.25it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.25it/s]
eager: 0.1527s, compiled: 0.0809s
HINT_SIZE (32, 1024) RUNTIME_SIZE (32, 1024) 1.887x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:21,  1.36it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:20,  1.36it/s]running benchmark:  10%|█         | 3/30 [00:02<00:19,  1.36it/s]running benchmark:  13%|█▎        | 4/30 [00:02<00:19,  1.36it/s]running benchmark:  17%|█▋        | 5/30 [00:03<00:18,  1.36it/s]running benchmark:  20%|██        | 6/30 [00:04<00:17,  1.36it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:16,  1.36it/s]running benchmark:  27%|██▋       | 8/30 [00:05<00:16,  1.36it/s]running benchmark:  30%|███       | 9/30 [00:06<00:15,  1.36it/s]running benchmark:  33%|███▎      | 10/30 [00:07<00:14,  1.36it/s]running benchmark:  37%|███▋      | 11/30 [00:08<00:13,  1.36it/s]running benchmark:  40%|████      | 12/30 [00:08<00:13,  1.36it/s]running benchmark:  43%|████▎     | 13/30 [00:09<00:12,  1.36it/s]running benchmark:  47%|████▋     | 14/30 [00:10<00:11,  1.36it/s]running benchmark:  50%|█████     | 15/30 [00:11<00:11,  1.36it/s]running benchmark:  53%|█████▎    | 16/30 [00:11<00:10,  1.36it/s]running benchmark:  57%|█████▋    | 17/30 [00:12<00:09,  1.36it/s]running benchmark:  60%|██████    | 18/30 [00:13<00:08,  1.36it/s]running benchmark:  63%|██████▎   | 19/30 [00:13<00:08,  1.36it/s]running benchmark:  67%|██████▋   | 20/30 [00:14<00:07,  1.36it/s]running benchmark:  70%|███████   | 21/30 [00:15<00:06,  1.36it/s]running benchmark:  73%|███████▎  | 22/30 [00:16<00:05,  1.36it/s]running benchmark:  77%|███████▋  | 23/30 [00:16<00:05,  1.36it/s]running benchmark:  80%|████████  | 24/30 [00:17<00:04,  1.36it/s]running benchmark:  83%|████████▎ | 25/30 [00:18<00:03,  1.36it/s]running benchmark:  87%|████████▋ | 26/30 [00:19<00:02,  1.36it/s]running benchmark:  90%|█████████ | 27/30 [00:19<00:02,  1.36it/s]running benchmark:  93%|█████████▎| 28/30 [00:20<00:01,  1.36it/s]running benchmark:  97%|█████████▋| 29/30 [00:21<00:00,  1.36it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.36it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.36it/s]
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.8597120046615601, "best_triton_pos": 1, "best_triton_time": 1.075935959815979, "best_triton_kernel": "triton_mm_12025", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(65536x768, 768x3072)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.8597 ms 100.0% 
  triton_mm_12025 1.0759 ms 79.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12024 1.3685 ms 62.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_12019 1.3725 ms 62.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12020 1.3732 ms 62.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_12026 1.3785 ms 62.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12022 1.4495 ms 59.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12023 1.4674 ms 58.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_12021 1.5398 ms 55.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12017 1.8492 ms 46.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.7142 seconds and 0.0004 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.852895975112915, "best_triton_pos": 1, "best_triton_time": 0.9624959826469421, "best_triton_kernel": "triton_mm_13382", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(65536x3072, 3072x768)
strides: [3072, 1], [1, 3072]
dtypes: torch.float32, torch.float32
  mm 0.8529 ms 100.0% 
  triton_mm_13382 0.9625 ms 88.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13383 1.1819 ms 72.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13381 1.2375 ms 68.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_13376 1.2807 ms 66.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13378 1.3818 ms 61.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13377 1.3977 ms 61.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_13379 1.4768 ms 57.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13380 1.4949 ms 57.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_13374 1.8256 ms 46.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.6954 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 16, "num_triton_choices": 15, "best_kernel": "mm", "best_time": 0.24643200635910034, "best_triton_pos": 1, "best_triton_time": 0.2945599853992462, "best_triton_kernel": "triton_mm_12010", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
AUTOTUNE mm(65536x768, 768x768)
strides: [768, 1], [1, 768]
dtypes: torch.float32, torch.float32
  mm 0.2464 ms 100.0% 
  triton_mm_12010 0.2946 ms 83.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12011 0.3364 ms 73.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12004 0.3365 ms 73.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12007 0.3460 ms 71.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12005 0.3575 ms 68.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_12008 0.3692 ms 66.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_12009 0.3743 ms 65.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_mm_12006 0.4139 ms 59.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_12002 0.4336 ms 56.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.5752 seconds and 0.0002 seconds precompiling for 16 choices
Autotune Choices Stats:
{"num_choices": 19, "num_triton_choices": 18, "best_kernel": "triton_bmm_11961", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 3.2265279293060303, "best_triton_pos": 0}
AUTOTUNE bmm(384x2048x64, 384x64x2048)
strides: [64*s22, 64, 1], [64*s22, s22, 1]
dtypes: torch.float32, torch.float32
  triton_bmm_11961 3.2265 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_11962 3.2324 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
  bmm 3.3633 ms 95.9% 
  triton_bmm_11956 3.6787 ms 87.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_11963 3.6914 ms 87.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_11965 3.7906 ms 85.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_11967 3.8302 ms 84.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_11966 3.9365 ms 82.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_11955 4.0953 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_11964 4.0969 ms 78.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
SingleProcess AUTOTUNE benchmarking takes 1.1337 seconds and 0.0002 seconds precompiling for 19 choices
Autotune Choices Stats:
{"num_choices": 15, "num_triton_choices": 14, "best_kernel": "bmm", "best_time": 3.4006080627441406, "best_triton_pos": 1, "best_triton_time": 3.613215923309326, "best_triton_kernel": "triton_bmm_11985", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8"}
AUTOTUNE bmm(384x2048x2048, 384x2048x64)
strides: [s22**2, s22, 1], [64*s22, 64, 1]
dtypes: torch.float32, torch.float32
  bmm 3.4006 ms 100.0% 
  triton_bmm_11985 3.6132 ms 94.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
  triton_bmm_11995 3.7494 ms 90.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
  triton_bmm_11994 3.7929 ms 89.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_bmm_11993 3.7973 ms 89.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_11996 3.8487 ms 88.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_11984 4.0762 ms 83.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_11988 4.4719 ms 76.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_bmm_11990 4.6572 ms 73.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_bmm_11992 4.7324 ms 71.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 0.8452 seconds and 0.0002 seconds precompiling for 15 choices
Autotune Choices Stats:
{"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_13387", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.007296000141650438, "best_triton_pos": 0}
AUTOTUNE addmm(32x2, 32x768, 768x2)
strides: [0, 1], [768*s22, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_13387 0.0073 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_13393 0.0073 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
  triton_mm_13394 0.0079 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_13386 0.0086 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
  triton_mm_13390 0.0092 ms 79.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
  triton_mm_13392 0.0097 ms 75.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
  triton_mm_13385 0.0100 ms 72.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
  triton_mm_13391 0.0121 ms 60.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
  addmm 0.0131 ms 55.6% 
  bias_addmm 0.0136 ms 53.8% 
SingleProcess AUTOTUNE benchmarking takes 0.1372 seconds and 0.0002 seconds precompiling for 13 choices
Autotune Choices Stats:
{"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_13402", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 10.145279884338379, "best_triton_pos": 0}
AUTOTUNE addmm(65536x20005, 65536x768, 768x20005)
strides: [0, 1], [768, 1], [1, 768]
dtypes: torch.float32, torch.float32, torch.float32
  triton_mm_13402 10.1453 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13405 10.3338 ms 98.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13408 10.3720 ms 97.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13403 10.6133 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_13409 11.2133 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13406 11.9367 ms 85.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
  triton_mm_13400 12.2322 ms 82.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
  triton_mm_13404 13.6029 ms 74.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
  triton_mm_13401 13.7370 ms 73.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
  bias_addmm 15.8215 ms 64.1% 
SingleProcess AUTOTUNE benchmarking takes 2.3970 seconds and 0.0002 seconds precompiling for 17 choices
eager: 0.4932s, compiled: 0.2418s
HINT_SIZE (32, 1024) RUNTIME_SIZE (32, 2048) 2.040x
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 s22 64 []
scaled_mm s21*s22 768 768 []
scaled_mm s22 64 s22 []
scaled_mm s21*s22 768 768 []
scaled_mm s21*s22 3072 768 []
scaled_mm s21*s22 768 3072 []
scaled_mm s21 2 768 []
scaled_mm s21*s22 20005 768 []
running speedup_experiment with sizes: [torch.Size([2, 256]), torch.Size([2, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:26,  1.10it/s]running benchmark:  37%|███▋      | 11/30 [00:01<00:01, 14.49it/s]running benchmark:  70%|███████   | 21/30 [00:01<00:00, 28.16it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 24.82it/s]
eager: 0.0071s, compiled: 0.0029s
HINT_SIZE (32, 2048) RUNTIME_SIZE (2, 256) 2.418x
running speedup_experiment with sizes: [torch.Size([2, 1024]), torch.Size([2, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 54.02it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 53.99it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 53.95it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 53.89it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 53.88it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 53.89it/s]
eager: 0.0114s, compiled: 0.0068s
HINT_SIZE (32, 2048) RUNTIME_SIZE (2, 1024) 1.669x
running speedup_experiment with sizes: [torch.Size([2, 2048]), torch.Size([2, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 19.99it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 19.95it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 19.94it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 19.93it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 19.91it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 19.92it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:00, 19.92it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 19.93it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 19.93it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 19.93it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 19.94it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 19.93it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 19.91it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 19.92it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.92it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 19.92it/s]
eager: 0.0327s, compiled: 0.0169s
HINT_SIZE (32, 2048) RUNTIME_SIZE (2, 2048) 1.936x
running speedup_experiment with sizes: [torch.Size([8, 256]), torch.Size([8, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:00, 71.94it/s]running benchmark:  53%|█████▎    | 16/30 [00:00<00:00, 72.00it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 72.66it/s]running benchmark: 100%|██████████| 30/30 [00:00<00:00, 72.71it/s]
eager: 0.0078s, compiled: 0.0056s
HINT_SIZE (32, 2048) RUNTIME_SIZE (8, 256) 1.390x
running speedup_experiment with sizes: [torch.Size([8, 1024]), torch.Size([8, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:01, 15.95it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:01, 15.91it/s]running benchmark:  20%|██        | 6/30 [00:00<00:01, 15.90it/s]running benchmark:  27%|██▋       | 8/30 [00:00<00:01, 15.91it/s]running benchmark:  33%|███▎      | 10/30 [00:00<00:01, 15.90it/s]running benchmark:  40%|████      | 12/30 [00:00<00:01, 15.90it/s]running benchmark:  47%|████▋     | 14/30 [00:00<00:01, 15.90it/s]running benchmark:  53%|█████▎    | 16/30 [00:01<00:00, 15.90it/s]running benchmark:  60%|██████    | 18/30 [00:01<00:00, 15.90it/s]running benchmark:  67%|██████▋   | 20/30 [00:01<00:00, 15.90it/s]running benchmark:  73%|███████▎  | 22/30 [00:01<00:00, 15.90it/s]running benchmark:  80%|████████  | 24/30 [00:01<00:00, 15.89it/s]running benchmark:  87%|████████▋ | 26/30 [00:01<00:00, 15.89it/s]running benchmark:  93%|█████████▎| 28/30 [00:01<00:00, 15.89it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 15.89it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 15.90it/s]
eager: 0.0389s, compiled: 0.0234s
HINT_SIZE (32, 2048) RUNTIME_SIZE (8, 1024) 1.661x
running speedup_experiment with sizes: [torch.Size([8, 2048]), torch.Size([8, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:05,  5.30it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:05,  5.29it/s]running benchmark:  10%|█         | 3/30 [00:00<00:05,  5.29it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:04,  5.29it/s]running benchmark:  17%|█▋        | 5/30 [00:00<00:04,  5.29it/s]running benchmark:  20%|██        | 6/30 [00:01<00:04,  5.29it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:04,  5.29it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:04,  5.29it/s]running benchmark:  30%|███       | 9/30 [00:01<00:03,  5.29it/s]running benchmark:  33%|███▎      | 10/30 [00:01<00:03,  5.29it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:03,  5.29it/s]running benchmark:  40%|████      | 12/30 [00:02<00:03,  5.29it/s]running benchmark:  43%|████▎     | 13/30 [00:02<00:03,  5.29it/s]running benchmark:  47%|████▋     | 14/30 [00:02<00:03,  5.29it/s]running benchmark:  50%|█████     | 15/30 [00:02<00:02,  5.29it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:02,  5.29it/s]running benchmark:  57%|█████▋    | 17/30 [00:03<00:02,  5.29it/s]running benchmark:  60%|██████    | 18/30 [00:03<00:02,  5.29it/s]running benchmark:  63%|██████▎   | 19/30 [00:03<00:02,  5.29it/s]running benchmark:  67%|██████▋   | 20/30 [00:03<00:01,  5.29it/s]running benchmark:  70%|███████   | 21/30 [00:03<00:01,  5.29it/s]running benchmark:  73%|███████▎  | 22/30 [00:04<00:01,  5.29it/s]running benchmark:  77%|███████▋  | 23/30 [00:04<00:01,  5.29it/s]running benchmark:  80%|████████  | 24/30 [00:04<00:01,  5.29it/s]running benchmark:  83%|████████▎ | 25/30 [00:04<00:00,  5.29it/s]running benchmark:  87%|████████▋ | 26/30 [00:04<00:00,  5.29it/s]running benchmark:  90%|█████████ | 27/30 [00:05<00:00,  5.29it/s]running benchmark:  93%|█████████▎| 28/30 [00:05<00:00,  5.29it/s]running benchmark:  97%|█████████▋| 29/30 [00:05<00:00,  5.29it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.30it/s]running benchmark: 100%|██████████| 30/30 [00:05<00:00,  5.29it/s]
eager: 0.1248s, compiled: 0.0631s
HINT_SIZE (32, 2048) RUNTIME_SIZE (8, 2048) 1.977x
running speedup_experiment with sizes: [torch.Size([32, 256]), torch.Size([32, 256])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:  10%|█         | 3/30 [00:00<00:01, 24.40it/s]running benchmark:  20%|██        | 6/30 [00:00<00:00, 24.45it/s]running benchmark:  30%|███       | 9/30 [00:00<00:00, 24.44it/s]running benchmark:  40%|████      | 12/30 [00:00<00:00, 24.45it/s]running benchmark:  50%|█████     | 15/30 [00:00<00:00, 24.47it/s]running benchmark:  60%|██████    | 18/30 [00:00<00:00, 24.47it/s]running benchmark:  70%|███████   | 21/30 [00:00<00:00, 24.47it/s]running benchmark:  80%|████████  | 24/30 [00:00<00:00, 24.49it/s]running benchmark:  90%|█████████ | 27/30 [00:01<00:00, 24.49it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 24.48it/s]running benchmark: 100%|██████████| 30/30 [00:01<00:00, 24.47it/s]
eager: 0.0208s, compiled: 0.0195s
HINT_SIZE (32, 2048) RUNTIME_SIZE (32, 256) 1.065x
running speedup_experiment with sizes: [torch.Size([32, 1024]), torch.Size([32, 1024])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:07,  4.11it/s]running benchmark:   7%|▋         | 2/30 [00:00<00:06,  4.10it/s]running benchmark:  10%|█         | 3/30 [00:00<00:06,  4.10it/s]running benchmark:  13%|█▎        | 4/30 [00:00<00:06,  4.10it/s]running benchmark:  17%|█▋        | 5/30 [00:01<00:06,  4.10it/s]running benchmark:  20%|██        | 6/30 [00:01<00:05,  4.10it/s]running benchmark:  23%|██▎       | 7/30 [00:01<00:05,  4.10it/s]running benchmark:  27%|██▋       | 8/30 [00:01<00:05,  4.10it/s]running benchmark:  30%|███       | 9/30 [00:02<00:05,  4.10it/s]running benchmark:  33%|███▎      | 10/30 [00:02<00:04,  4.10it/s]running benchmark:  37%|███▋      | 11/30 [00:02<00:04,  4.10it/s]running benchmark:  40%|████      | 12/30 [00:02<00:04,  4.10it/s]running benchmark:  43%|████▎     | 13/30 [00:03<00:04,  4.10it/s]running benchmark:  47%|████▋     | 14/30 [00:03<00:03,  4.10it/s]running benchmark:  50%|█████     | 15/30 [00:03<00:03,  4.10it/s]running benchmark:  53%|█████▎    | 16/30 [00:03<00:03,  4.10it/s]running benchmark:  57%|█████▋    | 17/30 [00:04<00:03,  4.10it/s]running benchmark:  60%|██████    | 18/30 [00:04<00:02,  4.10it/s]running benchmark:  63%|██████▎   | 19/30 [00:04<00:02,  4.10it/s]running benchmark:  67%|██████▋   | 20/30 [00:04<00:02,  4.10it/s]running benchmark:  70%|███████   | 21/30 [00:05<00:02,  4.10it/s]running benchmark:  73%|███████▎  | 22/30 [00:05<00:01,  4.10it/s]running benchmark:  77%|███████▋  | 23/30 [00:05<00:01,  4.10it/s]running benchmark:  80%|████████  | 24/30 [00:05<00:01,  4.10it/s]running benchmark:  83%|████████▎ | 25/30 [00:06<00:01,  4.10it/s]running benchmark:  87%|████████▋ | 26/30 [00:06<00:00,  4.10it/s]running benchmark:  90%|█████████ | 27/30 [00:06<00:00,  4.10it/s]running benchmark:  93%|█████████▎| 28/30 [00:06<00:00,  4.10it/s]running benchmark:  97%|█████████▋| 29/30 [00:07<00:00,  4.10it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.10it/s]running benchmark: 100%|██████████| 30/30 [00:07<00:00,  4.10it/s]
eager: 0.1525s, compiled: 0.0904s
HINT_SIZE (32, 2048) RUNTIME_SIZE (32, 1024) 1.688x
running speedup_experiment with sizes: [torch.Size([32, 2048]), torch.Size([32, 2048])]
running benchmark:   0%|          | 0/30 [00:00<?, ?it/s]running benchmark:   3%|▎         | 1/30 [00:00<00:21,  1.35it/s]running benchmark:   7%|▋         | 2/30 [00:01<00:20,  1.35it/s]running benchmark:  10%|█         | 3/30 [00:02<00:20,  1.35it/s]running benchmark:  13%|█▎        | 4/30 [00:02<00:19,  1.35it/s]running benchmark:  17%|█▋        | 5/30 [00:03<00:18,  1.35it/s]running benchmark:  20%|██        | 6/30 [00:04<00:17,  1.35it/s]running benchmark:  23%|██▎       | 7/30 [00:05<00:17,  1.35it/s]running benchmark:  27%|██▋       | 8/30 [00:05<00:16,  1.35it/s]running benchmark:  30%|███       | 9/30 [00:06<00:15,  1.35it/s]running benchmark:  33%|███▎      | 10/30 [00:07<00:14,  1.35it/s]running benchmark:  37%|███▋      | 11/30 [00:08<00:14,  1.35it/s]running benchmark:  40%|████      | 12/30 [00:08<00:13,  1.35it/s]running benchmark:  43%|████▎     | 13/30 [00:09<00:12,  1.35it/s]running benchmark:  47%|████▋     | 14/30 [00:10<00:11,  1.35it/s]running benchmark:  50%|█████     | 15/30 [00:11<00:11,  1.35it/s]running benchmark:  53%|█████▎    | 16/30 [00:11<00:10,  1.35it/s]running benchmark:  57%|█████▋    | 17/30 [00:12<00:09,  1.35it/s]running benchmark:  60%|██████    | 18/30 [00:13<00:08,  1.35it/s]running benchmark:  63%|██████▎   | 19/30 [00:14<00:08,  1.35it/s]running benchmark:  67%|██████▋   | 20/30 [00:14<00:07,  1.35it/s]running benchmark:  70%|███████   | 21/30 [00:15<00:06,  1.35it/s]running benchmark:  73%|███████▎  | 22/30 [00:16<00:05,  1.35it/s]running benchmark:  77%|███████▋  | 23/30 [00:17<00:05,  1.35it/s]running benchmark:  80%|████████  | 24/30 [00:17<00:04,  1.35it/s]running benchmark:  83%|████████▎ | 25/30 [00:18<00:03,  1.35it/s]running benchmark:  87%|████████▋ | 26/30 [00:19<00:02,  1.35it/s]running benchmark:  90%|█████████ | 27/30 [00:20<00:02,  1.35it/s]running benchmark:  93%|█████████▎| 28/30 [00:20<00:01,  1.35it/s]running benchmark:  97%|█████████▋| 29/30 [00:21<00:00,  1.35it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.35it/s]running benchmark: 100%|██████████| 30/30 [00:22<00:00,  1.35it/s]
eager: 0.4929s, compiled: 0.2470s
HINT_SIZE (32, 2048) RUNTIME_SIZE (32, 2048) 1.996x
2.490x 1.742x 1.690x 1.844x 1.750x 1.674x 1.439x 1.805x 1.677x 2.867x 1.849x 1.899x 1.788x 1.828x 1.887x 1.405x 1.848x 1.855x 2.299x 1.628x 1.952x 1.354x 1.619x 1.927x 1.034x 1.615x 1.924x 2.757x 1.457x 1.370x 1.926x 1.397x 1.382x 1.444x 1.422x 1.394x 2.421x 1.815x 1.955x 1.762x 1.836x 2.010x 1.385x 1.889x 2.039x 2.386x 1.667x 1.937x 1.374x 1.662x 1.978x 1.065x 1.690x 1.996x 2.492x 1.821x 1.771x 1.921x 1.865x 1.744x 1.576x 1.908x 1.738x 2.414x 1.803x 1.946x 1.736x 1.825x 2.008x 1.360x 1.887x 2.040x 2.418x 1.669x 1.936x 1.390x 1.661x 1.977x 1.065x 1.688x 1.996x
